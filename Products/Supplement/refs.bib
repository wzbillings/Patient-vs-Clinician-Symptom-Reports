
@article{afonso2012,
  title = {The Use of Classification and Regression Trees to Predict the Likelihood of Seasonal Influenza},
  author = {Afonso, Anna M and Ebell, Mark H and Gonzales, Ralph and Stein, John and Genton, Blaise and Senn, Nicolas},
  year = {2012},
  month = dec,
  journal = {Family Practice},
  volume = {29},
  number = {6},
  pages = {671--677},
  issn = {0263-2136},
  doi = {10.1093/fampra/cms020},
  abstract = {Individual signs and symptoms are of limited value for the diagnosis of influenza.To develop a decision tree for the diagnosis of influenza based on a classification and regression tree (CART) analysis.Data from two previous similar cohort studies were assembled into a single dataset. The data were randomly divided into a development set (70\%) and a validation set (30\%). We used CART analysis to develop three models that maximize the number of patients who do not require diagnostic testing prior to treatment decisions. The validation set was used to evaluate overfitting of the model to the training set.Model 1 has seven terminal nodes based on temperature, the onset of symptoms and the presence of chills, cough and myalgia. Model 2 was a simpler tree with only two splits based on temperature and the presence of chills. Model 3 was developed with temperature as a dichotomous variable ({$\geq$}38\textdegree C) and had only two splits based on the presence of fever and myalgia. The area under the receiver operating characteristic curves (AUROCC) for the development and validation sets, respectively, were 0.82 and 0.80 for Model 1, 0.75 and 0.76 for Model 2 and 0.76 and 0.77 for Model 3. Model 2 classified 67\% of patients in the validation group into a high- or low-risk group compared with only 38\% for Model 1 and 54\% for Model 3.A simple decision tree (Model 2) classified two-thirds of patients as low or high risk and had an AUROCC of 0.76. After further validation in an independent population, this CART model could support clinical decision making regarding influenza, with low-risk patients requiring no further evaluation for influenza and high-risk patients being candidates for empiric symptomatic or drug therapy.},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\I3IHCQGM\\Afonso et al. - 2012 - The use of classification and regression trees to .pdf;C\:\\Users\\Zane\\Zotero\\storage\\75MQYF8A\\452140.html}
}

@article{bandayrel2013,
  title = {Information Technology Systems for Critical Care Triage and Medical Response during an Influenza Pandemic: A Review of Current Systems},
  shorttitle = {Information Technology Systems for Critical Care Triage and Medical Response during an Influenza Pandemic},
  author = {Bandayrel, Kristofer and Lapinsky, Stephen and Christian, Michael},
  year = {2013},
  month = jun,
  journal = {Disaster Med Public Health Prep},
  volume = {7},
  number = {3},
  pages = {287--291},
  issn = {1938-744X},
  doi = {10.1001/dmp.2011.45},
  abstract = {OBJECTIVES: To assess local, state, federal, and global pandemic influenza preparedness by identifying pandemic plans at the local, state, federal, and global levels, and to identify any information technology (IT) systems in these plans to support critical care triage during an influenza pandemic in the Canadian province of Ontario. METHODS: The authors used advanced MEDLINE and Google search strategies and conducted a comprehensive review of key pandemic influenza Web sites. Descriptive data extraction and analysis for IT systems were conducted on all of the included pandemic plans. RESULTS: A total of 155 pandemic influenza plans were reviewed: 29 local, 62 state, 63 federal, and 1 global. We found 70 plans that examined IT systems (10 local, 33 state, 26 federal, 1 global), and 85 that did not (19 local, 29 state, 37 federal). Of the 70 plans, 64 described surveillance systems (10 local, 32 state, 21 federal, 1 global), 2 described patient data collection systems (1 state, 1 federal); 4 described other types of IT systems (4 federal), and none were intended for triage. CONCLUSIONS: Although several pandemic plans have been drafted, the majority are high-level general documents that do not describe IT systems. The plans that discuss IT systems focus strongly on surveillance, which fails to recognize the needs of a health care system responding to an influenza pandemic. The best examples of the types of IT systems to guide decision making during a pandemic were found in the Kansas and the Czech Republic pandemic plans, because these systems were designed to collect both patient and surveillance data. Although Ontario has yet to develop such an IT system, several IT systems are in place that could be leveraged to support critical care triage and medical response during an influenza pandemic.},
  langid = {english},
  pmid = {21709055},
  keywords = {Critical Care,Databases; Factual,Hospital Information Systems,Humans,Influenza; Human,Ontario,Pandemics,Triage}
}

@article{bland1995,
  title = {Comparing Methods of Measurement: Why Plotting Difference against Standard Method Is Misleading},
  shorttitle = {Comparing Methods of Measurement},
  author = {Bland, J. M. and Altman, D. G.},
  year = {1995},
  month = oct,
  journal = {The Lancet},
  volume = {346},
  number = {8982},
  pages = {1085--1087},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(95)91748-9},
  abstract = {When comparing a new method of measurement with a standard method, one of the things we want to know is whether the difference between the measurements by the two methods is related to the magnitude of the measurement. A plot of the difference against the standard measurement is sometimes suggested, but this will always appear to show a relation between difference and magnitude when there is none. A plot of the difference against the average of the standard and new measurements is unlikely to mislead in this way. We show this theoretically and by a practical example.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\SQCCIJIQ\\Bland and Altman - 1995 - Comparing methods of measurement why plotting dif.pdf;C\:\\Users\\Zane\\Zotero\\storage\\2Y9SPBTL\\S0140673695917489.html}
}

@article{blozik2012,
  title = {Influenza Surveillance Using Data from a Telemedicine Centre},
  author = {Blozik, Eva and Grandchamp, Chantal and {von Overbeck}, Jan},
  year = {2012},
  month = apr,
  journal = {Int J Public Health},
  volume = {57},
  number = {2},
  pages = {447--452},
  issn = {1661-8564},
  doi = {10.1007/s00038-011-0240-1},
  abstract = {OBJECTIVES: This study aimed at investigating whether data from medical teleconsultations may contribute to influenza surveillance. METHODS: International Classification of Primary Care 2nd Edition (ICPC-2) codes were used to analyse the proportion of teleconsultations due to influenza-related symptoms. Results were compared with the weekly Swiss Sentinel reports. RESULTS: When using the ICPC-2 code for fever we could reproduce the seasonal influenza peaks of the winter seasons 07/08, 08/09 and 09/10 as depicted by the Sentinel data. For the pandemic influenza 09/10, we detected a much higher first peak in summer 2009 which correlated with a potential underreporting in the Sentinel system. CONCLUSIONS: ICPC-2 data from medical teleconsultations allows influenza surveillance in real time and correlates very well with the Swiss Sentinel system.},
  langid = {english},
  pmid = {21318326},
  keywords = {Humans,Influenza; Human,Pandemics,Population Surveillance,Switzerland,Telemedicine},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\XUT9SPEQ\\Blozik et al. - 2012 - Influenza surveillance using data from a telemedic.pdf}
}

@article{brunetti2015,
  title = {2014 {{Failed Influenza Vaccination Winter Campaign}}: {{Impact}} on {{Emergency Medical Service Calls Assessed}} by {{Telemedicine}}},
  shorttitle = {2014 {{Failed Influenza Vaccination Winter Campaign}}},
  author = {Brunetti, Natale Daniele and Dellegrottaglie, Giulia and De Gennaro, Luisa and Gaglione, Antonio and Di Biase, Matteo},
  year = {2015},
  month = sep,
  journal = {Epidemiology},
  volume = {26},
  number = {5},
  pages = {e61-62},
  issn = {1531-5487},
  doi = {10.1097/EDE.0000000000000347},
  langid = {english},
  pmid = {26164545},
  keywords = {Acute Disease,Cardiovascular Diseases,Emergency Medical Services,Humans,Influenza; Human,Italy,Mass Vaccination,Patient Acceptance of Health Care,Seasons,Telemedicine}
}

@article{byrt1993,
  title = {Bias, Prevalence and Kappa},
  author = {Byrt, T. and Bishop, J. and Carlin, J. B.},
  year = {1993},
  month = may,
  journal = {J Clin Epidemiol},
  volume = {46},
  number = {5},
  pages = {423--429},
  issn = {0895-4356},
  doi = {10.1016/0895-4356(93)90018-v},
  abstract = {Since the introduction of Cohen's kappa as a chance-adjusted measure of agreement between two observers, several "paradoxes" in its interpretation have been pointed out. The difficulties occur because kappa not only measures agreement but is also affected in complex ways by the presence of bias between observers and by the distributions of data across the categories that are used ("prevalence"). In this paper, new indices that provide independent measures of bias and prevalence, as well as of observed agreement, are defined and a simple formula is derived that expresses kappa in terms of these three indices. When comparisons are made between agreement studies it can be misleading to report kappa values alone, and it is recommended that researchers also include quantitative indicators of bias and prevalence.},
  langid = {english},
  pmid = {8501467},
  keywords = {Data Interpretation; Statistical,Humans,Mathematics,Observer Variation,Prevalence}
}

@article{cai2022,
  title = {The Impact of a Rapid Home Test on Telehealth Decision-Making for Influenza: A Clinical Vignette Study},
  shorttitle = {The Impact of a Rapid Home Test on Telehealth Decision-Making for Influenza},
  author = {Cai, Xinyan and Ebell, Mark H. and Geyer, Rachel E. and Thompson, Matthew and Gentile, Nicole L. and Lutz, Barry},
  year = {2022},
  month = apr,
  journal = {BMC Prim Care},
  volume = {23},
  pages = {75},
  issn = {2731-4553},
  doi = {10.1186/s12875-022-01675-1},
  abstract = {Background Home testing for influenza has the potential to aid triage and management decisions for patients with influenza-like illness. As yet, little is known about the effect of the home influenza testing on clinical decision-making via telehealth. The goal of this study was to determine the clinicians' decision thresholds for influenza and whether the availability of a home influenza test affects clinical decisions. Methods We identified primary care physicians at 4 different sites in the US, largely via in-person continuing education meetings. Clinicians were asked for each vignette whether to treat empirically (``rule in''), ask the patient come to the clinic for further evaluation (``test''), or neither test nor treat (``rule out''). They were then given the results of a home influenza test, and were again asked to select from these three options. We measured the agreement of physician estimates of the likelihood of influenza with the probability based on a clinical prediction model. The test and treatment thresholds of influenza were determined based on mixed-effect logistic regressions. Results In total, 202 clinicians made 570 sets of clinical decisions. Agreement between estimated and actual probability of influenza was fair. The test and treatment thresholds were 24\% (95\% CI: 22\% to 25\%) and 63\% (95\% CI: 58\% to 65\%) before revealing the actual likelihood of influenza. After providing the results of a home flu test the thresholds were similar, 26\% (95\% CI: 24\% to 29\%) and 59\% (95\% CI: 56\% to 62\%). However, approximately half of clinicians changed their cliical management decision after being given the home influenza test result, largely by categorizing more patients in the ``rule out'' and ``rule in'' groups, and reducing the need for in-person evaluation from 41\% of patients to only 20\%. Conclusion In the context of a telehealth visit for a patient with influenza-like illness, we identified a test threshold of approximately 25\% and a treatment threshold of approximately 60\%. Adding the home influenza test results reduced uncertainty and significantly decreased the need for in-person visits. Supplementary Information The online version contains supplementary material available at 10.1186/s12875-022-01675-1.},
  pmcid = {PMC9006488},
  pmid = {35418027},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\AI94KNJJ\\Cai et al. - 2022 - The impact of a rapid home test on telehealth deci.pdf}
}

@article{challen2007,
  title = {Clinical Review: Mass Casualty Triage--Pandemic Influenza and Critical Care},
  shorttitle = {Clinical Review},
  author = {Challen, Kirsty and Bentley, Andrew and Bright, John and Walter, Darren},
  year = {2007},
  journal = {Crit Care},
  volume = {11},
  number = {2},
  pages = {212},
  issn = {1466-609X},
  doi = {10.1186/cc5732},
  abstract = {Worst case scenarios for pandemic influenza planning in the US involve over 700,000 patients requiring mechanical ventilation. UK planning predicts a 231\% occupancy of current level 3 (intensive care unit) bed capacity. Critical care planners need to recognise that mortality is likely to be high and the risk to healthcare workers significant. Contingency planning should, therefore, be multi-faceted, involving a robust health command structure, the facility to expand critical care provision in terms of space, equipment and staff and cohorting of affected patients in the early stages. It should also be recognised that despite this expansion of critical care, demand will exceed supply and a process for triage needs to be developed that is valid, reproducible, transparent and consistent with distributive justice. We advocate the development and validation of physiological scores for use as a triage tool, coupled with candid public discussion of the process.},
  langid = {english},
  pmcid = {PMC2206465},
  pmid = {17490495},
  keywords = {Critical Care,Disease Outbreaks,Global Health,Health Planning Organizations,Humans,Influenza; Human,Intensive Care Units,Triage},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\CNEFQDC7\\Challen et al. - 2007 - Clinical review mass casualty triage--pandemic in.pdf}
}

@article{chicco2020,
  title = {The Advantages of the {{Matthews}} Correlation Coefficient ({{MCC}}) over {{F1}} Score and Accuracy in Binary Classification Evaluation},
  author = {Chicco, Davide and Jurman, Giuseppe},
  year = {2020},
  month = jan,
  journal = {BMC Genomics},
  volume = {21},
  pages = {6},
  issn = {1471-2164},
  doi = {10.1186/s12864-019-6413-7},
  abstract = {Background To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets. Results The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset. Conclusions In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
  pmcid = {PMC6941312},
  pmid = {31898477},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\9CL7JN6C\\Chicco and Jurman - 2020 - The advantages of the Matthews correlation coeffic.pdf}
}

@article{chicco2021,
  title = {The {{Matthews}} Correlation Coefficient ({{MCC}}) Is More Reliable than Balanced Accuracy, Bookmaker Informedness, and Markedness in Two-Class Confusion Matrix Evaluation},
  author = {Chicco, Davide and T{\"o}tsch, Niklas and Jurman, Giuseppe},
  year = {2021},
  month = feb,
  journal = {BioData Mining},
  volume = {14},
  number = {1},
  pages = {13},
  issn = {1756-0381},
  doi = {10.1186/s13040-021-00244-z},
  abstract = {Evaluating binary classifications is a pivotal task in statistics and machine learning, because it can influence decisions in multiple areas, including for example prognosis or therapies of patients in critical conditions. The scientific community has not agreed on a general-purpose statistical indicator for evaluating two-class confusion matrices (having true positives, true negatives, false positives, and false negatives) yet, even if advantages of the Matthews correlation coefficient (MCC) over accuracy and F1 score have already been shown.In this manuscript, we reaffirm that MCC is a robust metric that summarizes the classifier performance in a single value, if positive and negative cases are of equal importance. We compare MCC to other metrics which value positive and negative cases equally: balanced accuracy (BA), bookmaker informedness (BM), and markedness (MK). We explain the mathematical relationships between MCC and these indicators, then show some use cases and a bioinformatics scenario where these metrics disagree and where MCC generates a more informative response.Additionally, we describe three exceptions where BM can be more appropriate: analyzing classifications where dataset prevalence is unrepresentative, comparing classifiers on different datasets, and assessing the random guessing level of a classifier. Except in these cases, we believe that MCC is the most informative among the single metrics discussed, and suggest it as standard measure for scientists of all fields. A Matthews correlation coefficient close to +1, in fact, means having high values for all the other confusion matrix metrics. The same cannot be said for balanced accuracy, markedness, bookmaker informedness, accuracy and F1 score.},
  keywords = {Balanced accuracy,Binary classification,Bookmaker informedness,Confusion matrix,Machine learning,Markedness,Matthews correlation coefficient},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\SF649B2G\\Chicco et al. - 2021 - The Matthews correlation coefficient (MCC) is more.pdf;C\:\\Users\\Zane\\Zotero\\storage\\6CXQVLVW\\s13040-021-00244-z.html}
}

@article{choo2020,
  title = {Influenza {{Screening}} via {{Deep Learning Using}} a {{Combination}} of {{Epidemiological}} and {{Patient-Generated Health Data}}: {{Development}} and {{Validation Study}}},
  shorttitle = {Influenza {{Screening}} via {{Deep Learning Using}} a {{Combination}} of {{Epidemiological}} and {{Patient-Generated Health Data}}},
  author = {Choo, Hyunwoo and Kim, Myeongchan and Choi, Jiyun and Shin, Jaewon and Shin, Soo-Yong},
  year = {2020},
  month = oct,
  journal = {J Med Internet Res},
  volume = {22},
  number = {10},
  pages = {e21369},
  issn = {1438-8871},
  doi = {10.2196/21369},
  abstract = {BACKGROUND: Screening for influenza in primary care is challenging due to the low sensitivity of rapid antigen tests and the lack of proper screening tests. OBJECTIVE: The aim of this study was to develop a machine learning-based screening tool using patient-generated health data (PGHD) obtained from a mobile health (mHealth) app. METHODS: We trained a deep learning model based on a gated recurrent unit to screen influenza using PGHD, including each patient's fever pattern and drug administration records. We used meteorological data and app-based surveillance of the weekly number of patients with influenza. We defined a single episode as the set of consecutive days, including the day the user was diagnosed with influenza or another disease. Any record a user entered 24 hours after his or her last record was considered to be the start of a new episode. Each episode contained data on the user's age, gender, weight, and at least one body temperature record. The total number of episodes was 6657. Of these, there were 3326 episodes within which influenza was diagnosed. We divided these episodes into 80\% training sets (2664/3330) and 20\% test sets (666/3330). A 5-fold cross-validation was used on the training set. RESULTS: We achieved reliable performance with an accuracy of 82\%, a sensitivity of 84\%, and a specificity of 80\% in the test set. After the effect of each input variable was evaluated, app-based surveillance was observed to be the most influential variable. The correlation between the duration of input data and performance was not statistically significant (P=.09). CONCLUSIONS: These findings suggest that PGHD from an mHealth app could be a complementary tool for influenza screening. In addition, PGHD, along with traditional clinical data, could be used to improve health conditions.},
  langid = {english},
  pmcid = {PMC7661232},
  pmid = {33118941},
  keywords = {deep learning,Deep Learning,Female,Humans,influenza,Influenza; Human,Male,mHealth,Mobile Applications,mobile health,patient-generated health data,Retrospective Studies,screening tool,Telemedicine},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\GLIVII4S\\Choo et al. - 2020 - Influenza Screening via Deep Learning Using a Comb.pdf}
}

@article{chotpitayasunondh2021,
  title = {Influenza and {{COVID-19}}: {{What}} Does Co-Existence Mean?},
  shorttitle = {Influenza and {{COVID-19}}},
  author = {Chotpitayasunondh, Tawee and Fischer, Thea K{\o}lsen and Heraud, Jean-Michel and Hurt, Aeron C. and Monto, Arnold S. and Osterhaus, Albert and Shu, Yuelong and Tam, John S.},
  year = {2021},
  month = may,
  journal = {Influenza Other Respir Viruses},
  volume = {15},
  number = {3},
  pages = {407--412},
  issn = {1750-2659},
  doi = {10.1111/irv.12824},
  abstract = {The COVID-19 pandemic caused by the novel coronavirus SARS-CoV-2 continues to have a major impact on healthcare and social systems throughout the world. As the clinical and epidemiological features of COVID-19 have many parallels with influenza, it is important to ensure optimal management of both respiratory diseases as we anticipate their continued co-circulation. In particular, there is a need to ensure that effective surveillance and diagnostic capacities are in place to monitor these and other respiratory viruses, as this will underpin decisions on the appropriate clinical management of the respective diseases. As such, we propose a series of key recommendations for stakeholders, public health authorities, primary care physicians and surveillance bodies that will help mitigate the combined risks of concurrent influenza epidemics and the COVID-19 pandemic. We advocate the judicious use of influenza vaccines and antivirals, particularly among groups at high risk of complications, with healthcare workers also considered a priority for vaccination. It is likely that the increased use of emerging technologies such as telemedicine and contact tracing will permanently change our approach to managing infectious disease. The use of these technologies, alongside existing pharmaceutical strategies, will ensure that we achieve a holistic approach to the global public health measures needed to deal with the combined threat of influenza and COVID-19. Ensuring that this approach is optimal will be key as we move from a reactive pandemic response towards preparing for the long-term management of the remarkable clinical burden associated with these respiratory pathogens.},
  langid = {english},
  pmcid = {PMC8051702},
  pmid = {33128444},
  keywords = {antivirals,clinical management,Coinfection,COVID-19,Humans,influenza,Influenza; Human,SARS-CoV-2,surveillance},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\J7BNLF2K\\Chotpitayasunondh et al. - 2021 - Influenza and COVID-19 What does co-existence mea.pdf}
}

@article{cicchetti1994,
  title = {Guidelines, Criteria, and Rules of Thumb for Evaluating Normed and Standardized Assessment Instruments in Psychology},
  author = {Cicchetti, Domenic V.},
  year = {1994},
  journal = {Psychological Assessment},
  volume = {6},
  number = {4},
  pages = {284--290},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-134X},
  doi = {10.1037/1040-3590.6.4.284},
  abstract = {In the context of the development of prototypic assessment instruments in the areas of cognition, personality, and adaptive functioning, the issues of standardization, norming procedures, and the important psychometrics of test reliability and validity are evaluated critically. Criteria, guidelines, and simple rules of thumb are provided to assist the clinician faced with the challenge of choosing an appropriate test instrument for a given psychological assessment. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Measurement,Psychodiagnosis,Test Construction,Test Norms,Test Reliability,Test Standardization,Test Validity},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\7ABEM6RG\\1995-15835-001.html}
}

@article{cohen1960,
  title = {A {{Coefficient}} of {{Agreement}} for {{Nominal Scales}}},
  author = {Cohen, Jacob},
  year = {1960},
  month = apr,
  journal = {Educational and Psychological Measurement},
  volume = {20},
  number = {1},
  pages = {37--46},
  publisher = {{SAGE Publications Inc}},
  issn = {0013-1644},
  doi = {10.1177/001316446002000104},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\GG6236F6\\Cohen - 1960 - A Coefficient of Agreement for Nominal Scales.pdf}
}

@article{colbert2020,
  title = {Utility of Telemedicine in the {{COVID-19}} Era},
  author = {Colbert, Gates B. and {Venegas-Vera}, A. Verner and Lerma, Edgar V.},
  year = {2020},
  month = dec,
  journal = {Rev Cardiovasc Med},
  volume = {21},
  number = {4},
  pages = {583--587},
  issn = {1530-6550},
  doi = {10.31083/j.rcm.2020.04.188},
  abstract = {Previously it has been demonstrated that telehealth (TH) could help cover the gaps in health attention in remote locations. Today the expanded capabilities have transformed TH delivery, and from the beginning of the coronavirus pandemic, it has remained one of our biggest allies. Telehealth has become a central piece in patient healthcare delivery during COVID-19 pandemic era. Telehealth allows health care services to reach patients in their homes, keeping other patients safe through social distancing and maintaining self-quarantine. Within this administration of health, TH allows health care providers to focus more resources to pandemic usage and at the same time continue caring for the health of non COVID-19 patients. During this time, clinicians are expanding knowledge about TH capabilities, such as application of forward triage as a tool to avoid patient contact in emergency departments. While previously TH was mainly used for primary care needs, specialized and urgent care health is now being utilized more than ever before. These advantages comes with limitations, some of them include a limited physical exam, lack of access to diagnostic testing or imaging, and many other pitfalls and persistent unmet needs. The 2020 pandemic has led to significant improvements leading into the next generation of telemedicine.},
  langid = {english},
  pmid = {33388003},
  keywords = {COVID-19,Disease Management,healthcare,Humans,Pandemics,SARS-CoV-2,telehealth,Telemedicine},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\GWEREBF5\\Colbert et al. - 2020 - Utility of telemedicine in the COVID-19 era.pdf}
}

@article{cowley2019,
  title = {Methodological Standards for the Development and Evaluation of Clinical Prediction Rules: A Review of the Literature},
  shorttitle = {Methodological Standards for the Development and Evaluation of Clinical Prediction Rules},
  author = {Cowley, Laura E. and Farewell, Daniel M. and Maguire, Sabine and Kemp, Alison M.},
  year = {2019},
  month = aug,
  journal = {Diagnostic and Prognostic Research},
  volume = {3},
  number = {1},
  pages = {16},
  issn = {2397-7523},
  doi = {10.1186/s41512-019-0060-y},
  abstract = {Clinical prediction rules (CPRs) that predict the absolute risk of a clinical condition or future outcome for individual patients are abundant in the medical literature; however, systematic reviews have demonstrated shortcomings in the methodological quality and reporting of prediction studies. To maximise the potential and clinical usefulness of CPRs, they must be rigorously developed and validated, and their impact on clinical practice and patient outcomes must be evaluated. This review aims to present a comprehensive overview of the stages involved in the development, validation and evaluation of CPRs, and to describe in detail the methodological standards required at each stage, illustrated with examples where appropriate. Important features of the study design, statistical analysis, modelling strategy, data collection, performance assessment, CPR presentation and reporting are discussed, in addition to other, often overlooked aspects such as the acceptability, cost-effectiveness and longer-term implementation of CPRs, and their comparison with clinical judgement. Although the development and evaluation of a robust, clinically useful CPR is anything but straightforward, adherence to the plethora of methodological standards, recommendations and frameworks at each stage will assist in the development of a rigorous CPR that has the potential to contribute usefully to clinical practice and decision-making and have a positive impact on patient care.},
  keywords = {Clinical prediction rule,Diagnosis,Impact studies,Implementation,Model development,Model reporting,Model validation,Prediction model,Prognosis,Risk model,Study design},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\2J6H3HMA\\Cowley et al. - 2019 - Methodological standards for the development and e.pdf}
}

@article{cupp2020,
  title = {Planning for the next Influenza Pandemic: {{Using}} the Science and Art of Logistics},
  shorttitle = {Planning for the next Influenza Pandemic},
  author = {Cupp, O. Shawn and Predmore, Brad G.},
  year = {2020 Fall},
  journal = {Am J Disaster Med},
  volume = {14},
  number = {4},
  pages = {287--298},
  issn = {1932-149X},
  doi = {10.5055/ajdm.2019.0342},
  abstract = {The complexities and challenges for healthcare providers and their efforts to provide fundamental basic items to meet the logistical demands of an influenza pandemic are discussed in this article. The supply chain, planning, and alternatives for inevitable shortages are some of the considerations associated with this emergency mass critical care situation. The planning process and support for such events are discussed in detail with several recommendations obtained from the literature and the experience from recent mass casualty incidents (MCIs). The first step in this planning process is the development of specific triage requirements during an influenza pandemic. The second step is identification of logistical resources required during such a pandemic, which are then analyzed within the proposed logistics science and art model for planning purposes. Resources highlighted within the model include allocation and use of work force, bed space, intensive care unit assets, ventilators, personal protective equipment, and oxygen. The third step is using the model to discuss in detail possible workarounds, suitable substitutes, and resource allocation. An examination is also made of the ethics surrounding palliative care within the construction of an MCI and the factors that will inevitably determine rationing and prioritizing of these critical assets to palliative care patients.},
  langid = {english},
  pmid = {32803748},
  keywords = {Critical Care,Disaster Planning,Health Personnel,Humans,Influenza; Human,Mass Casualty Incidents,Pandemics,Triage}
}

@phdthesis{dale2018,
  title = {Diagnosis, {{Treatment}}, and {{Impact}} on {{Function}} of {{Influenza}} in a {{College Health Population}}},
  author = {Dale, Ariella Perry},
  year = {2018},
  school = {University of Georgia},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\VLPPGXT5\\dale_ariella_p_201805_phd.pdf}
}

@article{dale2019,
  title = {Impact of a {{Rapid Point}} of {{Care Test}} for {{Influenza}} on {{Guideline Consistent Care}} and {{Antibiotic Use}}},
  author = {Dale, Ariella Perry and Ebell, Mark and McKay, Brian and Handel, Andreas and Forehand, Ronald and Dobbin, Kevin},
  year = {2019},
  month = mar,
  journal = {J Am Board Fam Med},
  volume = {32},
  number = {2},
  pages = {226--233},
  publisher = {{American Board of Family Medicine}},
  issn = {1557-2625, 1558-7118},
  doi = {10.3122/jabfm.2019.02.180183},
  abstract = {Background: Rapid influenza diagnostic tests that detect the presence of viral antigens are currently used throughout the United States but have poor sensitivity. The objective of this study was to identify if the use of a new highly accurate rapid point of care test would significantly increase the likelihood of guideline consistent care. Methods: We prospectively recruited 300 students at a university health clinic who presented with cough and 1 influenza-like illness symptom between December 2016 and February 2017 to receive care guided by a rapid polymerase chain reaction (PCR) test. Of the 300 patients receiving the PCR test, 264 had complete medical records and were compared to 771 who received usual care. We used a logistic regression model to identify whether PCR guided care was associated with guideline consistent care, based on the appropriate use of oseltamivir and antibiotics. We also assessed whether PCR guided care decreased the likelihood of return visits within 2 weeks by patients. Results: Logistic regression revealed that the odds of receiving guideline supported care did not significantly increase for patients who received PCR guided care (adjusted odds ratio [aOR], 1.24; 95\% CI, 0.83\textendash 1.88). It significantly decreased the likelihood of an antibiotic prescription (aOR, 0.61; 95\% CI, 0.40\textendash 0.94), increased the likelihood of receiving oseltamivir (aOR, 1.57; 95\% CI, 1.09\textendash 2.28), and decreased the likelihood of return visit within 2 weeks (aOR, 0.19; 95\% CI, 0.04\textendash 0.81). Conclusions: The use of a rapid PCR test did not significantly improve the likelihood of guideline consistent care. However, independent of test outcome, patients who received the test were more likely to receive an antiviral and less likely to receive an antibiotic or have a return visit within 2 weeks.},
  chapter = {Original Research},
  copyright = {\textcopyright{} Copyright 2019 by the American Board of Family Medicine.},
  langid = {english},
  pmid = {30850459},
  keywords = {Antibiotics,Antiviral Agents,Diagnostic Tests,Influenza,Point of Care Testing,Polymerase Chain Reaction},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\69784YB8\\Dale et al. - 2019 - Impact of a Rapid Point of Care Test for Influenza.pdf;C\:\\Users\\Zane\\Zotero\\storage\\989XI8HP\\226.html}
}

@book{davison1997a,
  title = {Bootstrap {{Methods}} and Their {{Application}}},
  author = {Davison, A. C. and Hinkley, D. V.},
  year = {1997},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511802843},
  abstract = {Bootstrap methods are computer-intensive methods of statistical analysis, which use simulation to calculate standard errors, confidence intervals, and significance tests. The methods apply for any level of modelling, and so can be used for fully parametric, semiparametric, and completely nonparametric analysis. This 1997 book gives a broad and up-to-date coverage of bootstrap methods, with numerous applied examples, developed in a coherent way with the necessary theoretical basis. Applications include stratified data; finite populations; censored and missing data; linear, nonlinear, and smooth regression models; classification; time series and spatial problems. Special features of the book include: extensive discussion of significance tests and confidence intervals; material on various diagnostic methods; and methods for efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical and theoretical exercises. S-Plus programs for implementing the methods described in the text are available from the supporting website.},
  isbn = {978-0-521-57471-6}
}

@article{duffy2018,
  title = {In-{{Person Health Care}} as {{Option B}}},
  author = {Duffy, Sean and Lee, Thomas H.},
  year = {2018},
  month = jan,
  journal = {New England Journal of Medicine},
  volume = {378},
  number = {2},
  pages = {104--106},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMp1710735},
  pmid = {29320653},
  annotation = {\_eprint: https://doi.org/10.1056/NEJMp1710735},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\VUMMQ5GR\\Duffy and Lee - 2018 - In-Person Health Care as Option B.pdf;C\:\\Users\\Zane\\Zotero\\storage\\9VMQMKCI\\NEJMp1710735.html}
}

@article{dugas2020,
  title = {Derivation and {{Validation}} of a {{Clinical Decision Guideline}} for {{Influenza Testing}} in 4 {{US Emergency Departments}}},
  author = {Dugas, Andrea F and Hsieh, Yu-Hsiang and LoVecchio, Frank and Moran, Gregory J and Steele, Mark T and Talan, David A and Rothman, Richard E and {Emergency Department National Influenza Network Investigators} and Stubbs, Amy and Kemble, Laurie and Beckham, Danielle and Neal, Niccole and Mulrow, Mary and Krishnadasan, Anusha and Pathmarajah, Kavitha and Pathmarajah, Kavitha and Torrez, Raquel and Gonzalez, Eva and Martin, Gabina and Urzagaste, Noemi Quinteros and Furoy, Jacklyn and Hernandez, Mayra and Collison, Claire and Duval, Anna and Beard, Raphaelle and Avornu, Ama and Medina, Rebecca and McBryde, Breana},
  year = {2020},
  month = jan,
  journal = {Clinical Infectious Diseases},
  volume = {70},
  number = {1},
  pages = {49--58},
  issn = {1058-4838, 1537-6591},
  doi = {10.1093/cid/ciz171},
  abstract = {Background.{$\quad$} An accurate diagnosis of influenza is essential for appropriate antiviral treatment, in accordance with Centers for Disease Control and Prevention (CDC) guidelines. However, no clear guidance exists on which patients should be tested. We sought to develop a clinical decision guideline (CDG) to inform influenza testing decisions for those adult emergency department (ED) patients deemed appropriate for antiviral treatment by CDC guidelines. Methods.{$\quad$} A prospective cohort study was performed at 4 US EDs. From November 2013 to April 2014, we enrolled adult ED patients with fever or respiratory symptoms who met criteria for antiviral treatment, per 2013 CDC guidelines. All patients were tested for influenza using polymerase chain reaction. Data were randomly split into derivation (80\%) and validation (20\%) data sets. A discrete set of independent variables was selected by logistic regression, using the derivation set to create a scoring system, with a target sensitivity of at least 90\%. The derived CDG was then validated. Results.{$\quad$} Of 1941 enrolled participants, 183 (9.4\%) had influenza. The derived CDG included new or increased cough (2 points), headache (1 point), subjective fever (1 point), and triage temperature {$>$}100.4\textdegree C (1 point), with a score of {$\geq$}3 indicating influenza testing was warranted. The CDG had a sensitivity and specificity of 94.1\% and 36.6\%, respectively, in the derivation set and of 91.5\% and 34.6\%, respectively, in the validation set. Conclusions.{$\quad$} A CDG with high sensitivity was derived and validated. Incorporation into practice could standardize testing for high-risk patients in adult EDs during influenza seasons, potentially improving diagnoses and treatment. Clinical Trial Registration.{$\quad$}NCT01947049.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\6D69WBEG\\Dugas et al. - 2020 - Derivation and Validation of a Clinical Decision G.pdf}
}

@article{dugas2020a,
  title = {Derivation and {{Validation}} of a {{Clinical Decision Guideline}} for {{Influenza Testing}} in 4 {{US Emergency Departments}}},
  author = {Dugas, Andrea F. and Hsieh, Yu-Hsiang and LoVecchio, Frank and Moran, Gregory J. and Steele, Mark T. and Talan, David A. and Rothman, Richard E. and {Emergency Department National Influenza Network Investigators}},
  year = {2020},
  month = jan,
  journal = {Clin Infect Dis},
  volume = {70},
  number = {1},
  pages = {49--58},
  issn = {1537-6591},
  doi = {10.1093/cid/ciz171},
  abstract = {BACKGROUND: An accurate diagnosis of influenza is essential for appropriate antiviral treatment, in accordance with Centers for Disease Control and Prevention (CDC) guidelines. However, no clear guidance exists on which patients should be tested. We sought to develop a clinical decision guideline (CDG) to inform influenza testing decisions for those adult emergency department (ED) patients deemed appropriate for antiviral treatment by CDC guidelines. METHODS: A prospective cohort study was performed at 4 US EDs. From November 2013 to April 2014, we enrolled adult ED patients with fever or respiratory symptoms who met criteria for antiviral treatment, per 2013 CDC guidelines. All patients were tested for influenza using polymerase chain reaction. Data were randomly split into derivation (80\%) and validation (20\%) data sets. A discrete set of independent variables was selected by logistic regression, using the derivation set to create a scoring system, with a target sensitivity of at least 90\%. The derived CDG was then validated. RESULTS: Of 1941 enrolled participants, 183 (9.4\%) had influenza. The derived CDG included new or increased cough (2 points), headache (1 point), subjective fever (1 point), and triage temperature {$>$}100.4\textdegree C (1 point), with a score of {$\geq$}3 indicating influenza testing was warranted. The CDG had a sensitivity and specificity of 94.1\% and 36.6\%, respectively, in the derivation set and of 91.5\% and 34.6\%, respectively, in the validation set. CONCLUSIONS: A CDG with high sensitivity was derived and validated. Incorporation into practice could standardize testing for high-risk patients in adult EDs during influenza seasons, potentially improving diagnoses and treatment. CLINICAL TRIAL REGISTRATION: NCT01947049.},
  langid = {english},
  pmid = {30843056},
  keywords = {Adult,clinical decision guidelines,Emergency Service; Hospital,Fever,Humans,influenza,influenza-like illness (ILI),Influenza; Human,Prospective Studies,Triage}
}

@article{ebell2011,
  title = {A {{Systematic Review}} of {{Clinical Decision Rules}} for the {{Diagnosis}} of {{Influenza}}},
  author = {Ebell, M. H. and Afonso, A.},
  year = {2011},
  month = jan,
  journal = {The Annals of Family Medicine},
  volume = {9},
  number = {1},
  pages = {69--77},
  issn = {1544-1709, 1544-1717},
  doi = {10.1370/afm.1192},
  abstract = {PURPOSE In this study, we assessed whether multivariate models and clinical decision rules can be used to reliably diagnose influenza. METHODS We conducted a systematic review of MEDLINE, bibliographies of relevant studies, and previous meta-analyses. We searched the literature (1962-2010) for articles evaluating the accuracy of multivariate models, clinical decision rules, or simple heuristics for the diagnosis of influenza. Each author independently reviewed and abstracted data from each article; discrepancies were resolved by consensus discussion. Where possible, we calculated sensitivity, specificity, predictive value, likelihood ratios, and areas under the receiver operating characteristic curve. RESULTS A total of 12 studies met our inclusion criteria. No study prospectively validated a multivariate model or clinical decision rule, and no study performed a split-sample or bootstrap validation of such a model. Simple heuristics such as the so-called fever and cough rule and the fever, cough, and acute onset rule were each evaluated by several studies in populations of adults and children. The areas under the receiver operating characteristic curves were 0.70 and 0.79, respectively. We could not calculate a single summary estimate, however, as the diagnostic threshold varied among studies. CONCLUSIONS The fever and cough, and the fever, cough, and acute onset heuristics have modest accuracy, but summary estimates could not be calculated. Further research is needed to develop and prospectively validate clinical decision rules to identify patients requiring testing, empiric treatment, or neither.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\BDL3YDVF\\Ebell and Afonso - 2011 - A Systematic Review of Clinical Decision Rules for.pdf}
}

@article{ebell2012,
  title = {Development and {{Validation}} of a {{Clinical Decision Rule}} for the {{Diagnosis}} of {{Influenza}}},
  author = {Ebell, M. H. and Afonso, A. M. and Gonzales, R. and Stein, J. and Genton, B. and Senn, N.},
  year = {2012},
  month = jan,
  journal = {The Journal of the American Board of Family Medicine},
  volume = {25},
  number = {1},
  pages = {55--62},
  issn = {1557-2625, 1558-7118},
  doi = {10.3122/jabfm.2012.01.110161},
  abstract = {Methods: We combined data from 2 studies of influenza diagnosis in adult outpatients with suspected influenza: one set in California and one in Switzerland. Patients in both studies underwent a structured history and physical examination and had a reference standard test for influenza (polymerase chain reaction or culture). We randomly divided the dataset into derivation and validation groups and then evaluated simple heuristics and decision rules from previous studies and 3 rules based on our own multivariate analysis. Cutpoints for stratification of risk groups in each model were determined using the derivation group before evaluating them in the validation group. For each decision rule, the positive predictive value and likelihood ratio for influenza in low-, moderate-, and high-risk groups, and the percentage of patients allocated to each risk group, were reported. Results: The simple heuristics (fever and cough; fever, cough, and acute onset) were helpful when positive but not when negative. The most useful and accurate clinical rule assigned 2 points for fever plus cough, 2 points for myalgias, and 1 point each for duration {$<$}48 hours and chills or sweats. The risk of influenza was 8\% for 0 to 2 points, 30\% for 3 points, and 59\% for 4 to 6 points; the rule performed similarly in derivation and validation groups. Approximately two-thirds of patients fell into the low- or high-risk group and would not require further diagnostic testing. Conclusion: A simple, valid clinical rule can be used to guide point-of-care testing and empiric therapy for patients with suspected influenza. (J Am Board Fam Med 2012;25:55\textendash{} 62.)},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\CUGIV9DY\\Ebell et al. - 2012 - Development and Validation of a Clinical Decision .pdf}
}

@article{ebell2015,
  title = {A Novel Approach to the Determination of Clinical Decision Thresholds},
  author = {Ebell, Mark H. and Locatelli, Isabella and Senn, Nicolas},
  year = {2015},
  month = apr,
  journal = {BMJ Evidence-Based Medicine},
  volume = {20},
  number = {2},
  pages = {41--47},
  publisher = {{Royal Society of Medicine}},
  issn = {2515-446X, 2515-4478},
  doi = {10.1136/ebmed-2014-110140},
  abstract = {Extract Our objective was to determine the test and treatment thresholds for common acute primary care conditions. We presented 200 clinicians with a series of web-based clinical vignettes, describing patients with possible influenza, acute coronary syndrome (ACS), pneumonia, deep vein thrombosis (DVT) and urinary tract infection (UTI). We randomly varied the probability of disease and asked whether the clinician wanted to rule out disease, order tests or rule in disease. By randomly varying the probability, we obtained clinical decisions across a broad range of disease probabilities that we used to create threshold curves. For influenza, the test (4.5\% vs 32\%, p{$<$}0.001) and treatment (55\% vs 68\%, p=0.11) thresholds were lower for US compared with Swiss physicians. US physicians had somewhat higher test (3.8\% vs 0.7\%, p=0.107) and treatment (76\% vs 58\%, p=0.005) thresholds for ACS than Swiss physicians. For both groups, the range between test and treatment thresholds was greater for ACS than for influenza (which is sensible, given the consequences of incorrect diagnosis). For pneumonia, US physicians had a trend towards higher test thresholds and lower treatment thresholds (48\% vs 64\%, p=0.076) than Swiss physicians. The DVT and UTI scenarios did not provide easily interpretable data, perhaps due to poor wording of the vignettes. We have developed a novel approach for determining decision thresholds. We found important differences in thresholds for US and Swiss physicians that may be a function of differences in healthcare systems. Our results can also guide development of clinical decision rules and guidelines. Extract Our objective was to determine the test and treatment thresholds for common acute primary care conditions. We presented 200 clinicians with a series of web-based clinical vignettes, describing patients with possible influenza, acute coronary syndrome (ACS), pneumonia, deep vein thrombosis (DVT) and urinary tract infection (UTI). We randomly varied the probability of disease and asked whether the clinician wanted to rule out disease, order tests or rule in disease. By randomly varying the probability, we obtained clinical decisions across a broad range of disease probabilities that we used to create threshold curves. For influenza, the test (4.5\% vs 32\%, p{$<$}0.001) and treatment (55\% vs 68\%, p=0.11) thresholds were lower for US compared with Swiss physicians. US physicians had somewhat higher test (3.8\% vs 0.7\%, p=0.107) and treatment (76\% vs 58\%, p=0.005) thresholds for ACS than Swiss physicians. For both groups, the range between test and treatment thresholds was greater for ACS than for influenza (which is sensible, given the consequences of incorrect diagnosis). For pneumonia, US physicians had a trend towards higher test thresholds and lower treatment thresholds (48\% vs 64\%, p=0.076) than Swiss physicians. The DVT and UTI scenarios did not provide easily interpretable data, perhaps due to poor wording of the vignettes. We have developed a novel approach for determining decision thresholds. We found important differences in thresholds for US and Swiss physicians that may be a function of differences in healthcare systems. Our results can also guide development of clinical decision rules and guidelines.},
  chapter = {Methods},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  langid = {english},
  pmid = {25736042},
  keywords = {EPIDEMIOLOGY,GENERAL MEDICINE (see Internal Medicine),PRIMARY CARE,STATISTICS \& RESEARCH METHODS},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\J3KK7SIT\\104.full.pdf;C\:\\Users\\Zane\\Zotero\\storage\\QJD5NULG\\Ebell et al. - 2015 - A novel approach to the determination of clinical .pdf;C\:\\Users\\Zane\\Zotero\\storage\\RLCBAEKH\\41.html}
}

@article{ebell2021,
  title = {A {{Systematic Review}} of {{Clinical Prediction Rules}} for the {{Diagnosis}} of {{Influenza}}},
  author = {Ebell, Mark H. and Rahmatullah, Ivan and Cai, Xinyan and Bentivegna, Michelle and Hulme, Cassie and Thompson, Matthew and Lutz, Barry},
  year = {2021},
  month = nov,
  journal = {J Am Board Fam Med},
  volume = {34},
  number = {6},
  pages = {1123--1140},
  publisher = {{American Board of Family Medicine}},
  issn = {1557-2625, 1558-7118},
  doi = {10.3122/jabfm.2021.06.210110},
  abstract = {Background: Clinical prediction rules (CPRs) can assist clinicians by focusing their clinical evaluation on the most important signs and symptoms, and if used properly can reduce the need for diagnostic testing. This study aims to perform an updated systematic review of clinical prediction rules and classification and regression tree (CART) models for the diagnosis of influenza. Methods: We searched PubMed, CINAHL, and EMBASE databases. We identified prospective studies of patients presenting with suspected influenza or respiratory infection and that reported a CPR in the form of a risk score or CART-based algorithm. Studies had to report at a minimum the percentage of patients in each risk group with influenza. Studies were evaluated for inclusion and data were extracted by reviewers working in parallel. Accuracy was summarized descriptively; where not reported by the authors the area under the receiver operating characteristic curve (AUROCC), predictive values, and likelihood ratios were calculated. Results: We identified 10 studies that presented 14 CPRs. The most commonly included predictor variables were cough, fever, chills and/or sweats, myalgias, and acute onset, all which can be ascertained by phone or telehealth visit. Most CPRs had an AUROCC between 0.7 and 0.8, indicating good discrimination. However, only 1 rule has undergone prospective external validation, with limited success. Data reporting by the original studies was in some cases inadequate to determine measures of accuracy. Conclusions: Well-designed validation studies, studies of interrater reliability between telehealth an in-person assessment, and studies using novel data mining and artificial intelligence strategies are needed to improve diagnosis of this common and important infection.},
  chapter = {Original Research},
  copyright = {\textcopyright{} Copyright 2021 by the American Board of Family Medicine.},
  langid = {english},
  pmid = {34772768},
  keywords = {Clinical Decision Rules,Clinical Medicine,Influenza,Physical Examination,Prospective Studies,Respiratory Diseases,Systematic Reviews},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\VVEVBD64\\Ebell et al. - 2021 - A Systematic Review of Clinical Prediction Rules f.pdf;C\:\\Users\\Zane\\Zotero\\storage\\MPVSW2XT\\1123.html}
}

@article{gaitonde2019,
  title = {Influenza: {{Diagnosis}} and {{Treatment}}},
  shorttitle = {Influenza},
  author = {Gaitonde, David Y. and Moore, Faith C. and Morgan, Mackenzie K.},
  year = {2019},
  month = dec,
  journal = {Am Fam Physician},
  volume = {100},
  number = {12},
  pages = {751--758},
  issn = {1532-0650},
  abstract = {Influenza is an acute viral respiratory infection that causes significant morbidity and mortality worldwide. Three types of influenza cause disease in humans. Influenza A is the type most responsible for causing pandemics because of its high susceptibility to antigenic variation. Influenza is highly contagious, and the hallmark of infection is abrupt onset of fever, cough, chills or sweats, myalgias, and malaise. For most patients in the outpatient setting, the diagnosis is made clinically, and laboratory confirmation is not necessary. Laboratory testing may be useful in hospitalized patients with suspected influenza and in patients for whom a confirmed diagnosis will change treatment decisions. Rapid molecular assays are the preferred diagnostic tests because they can be done at the point of care, are highly accurate, and have fast results. Treatment with one of four approved anti-influenza drugs may be considered if the patient presents within 48 hours of symptom onset. The benefit of treatment is greatest when antiviral therapy is started within 24 hours of symptom onset. These drugs decrease the duration of illness by about 24 hours in otherwise healthy patients and may decrease the risk of serious complications. No anti-influenza drug has been proven superior. Annual influenza vaccination is recommended for all people six months and older who do not have contraindications.},
  langid = {english},
  pmid = {31845781},
  keywords = {Antiviral Agents,Humans,Influenza Vaccines,Influenza; Human}
}

@article{govaert1998,
  title = {The Predictive Value of Influenza Symptomatology in Elderly People.},
  author = {Govaert, T M and Dinant, G J and Aretz, K and Knottnerus, J A},
  year = {1998},
  month = feb,
  journal = {Family Practice},
  volume = {15},
  number = {1},
  pages = {16--22},
  issn = {0263-2136},
  doi = {10.1093/fampra/15.1.16},
  abstract = {OBJECTIVE: We aimed to determine the complex of symptoms which has the highest predictive value for the diagnosis of influenza. METHOD: A questionnaire study with questions regarding the symptomatology of influenza among patients aged 60 and older (n = 1838). Thirty-four participating GPs recorded the symptomatology of patients who came to their general practice with influenza-like complaints. The validity of the diagnostic conclusion of the GP, as well as the diagnostic validity of the criteria of the International Classification of Health Problems in Primary Care (ICHPPC-2) and the Sentinel Stations in The Netherlands, was determined with the help of the predictive value and odds ratio, using serologically confirmed influenza as the gold standard. The same method was used to determine which complex of symptoms has the highest predictive value for influenza. The results were verified using logistic regression analysis. RESULTS: The predictive value of the diagnostics of the GP amounted to 35\%. The predictive values of the diagnostics according to the criteria of the two classification methods were 24\% (Sentinel Stations) and 18\% (ICHPPC-2). Of the individual symptoms, the combination of fever, coughing and acute onset had the highest predictive value (30.3\%) for the diagnosis of influenza. CONCLUSION: It is recommended that the criteria of the Sentinel Stations in The Netherlands and the ICHPPC-2 be adapted in the following way: influenza is likely if, out of the entire complex of symptoms, at least fever, coughing and an acute onset occur.},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\IHJ2YA7V\\Govaert et al. - 1998 - The predictive value of influenza symptomatology i.pdf;C\:\\Users\\Zane\\Zotero\\storage\\D4M96GQE\\492638.html}
}

@article{gupta2021,
  title = {Telemedicine as a Component of Forward Triage in a Pandemic},
  author = {Gupta, Vikas S. and Popp, Elizabeth C. and Garcia, Elisa I. and Qashqai, Sahar and Ankrom, Christy and Wu, Tzu-Ching and Harting, Matthew T.},
  year = {2021},
  month = sep,
  journal = {Healthc (Amst)},
  volume = {9},
  number = {3},
  pages = {100567},
  issn = {2213-0772},
  doi = {10.1016/j.hjdsi.2021.100567},
  abstract = {OBJECTIVE(S): Coronavirus disease 2019 (COVID-19) presents an enormous challenge to healthcare systems globally. Optimizing access to healthcare while minimizing face-to-face patient encounters is critical to limiting exposures, conserving resources, and preserving health. We aimed to evaluate the utility of a COVID-focused telehealth program in avoiding potential in-person visits while maintaining high patient satisfaction. METHODS: All patients with COVID-related virtual visits at our center between March and May 2020 were included. Demographic, satisfaction, and clinical information were gathered using a modified, validated telehealth satisfaction questionnaire disseminated via email or telephone. Data were analyzed using Stata. RESULTS: Of 581 eligible patients, 180 (31\%) responded to the survey. Symptoms (73\%) and possible exposure (22\%) were the main reasons cited for pursuing a virtual visit; cough (44\%) and fever (36\%) were the most common presenting symptoms. Regarding patient satisfaction, most patients rated the experience as "very good" or "excellent", and 94\% of respondents said they would recommend COVID-focused triage through telehealth to others. Over 81\% of patients indicated that, if telehealth was not an option, they would have sought an in-person encounter. Ultimately, only 27\% of patients reported pursuing a face-to-face encounter after participating in the virtual visit. CONCLUSION: Based on patient self-reporting, telemedicine potentially prevented face-to-face COVID-related encounters. Patients expressed satisfaction with the virtual process and were less likely to pursue in-person consultation. Leveraging a telehealth strategy for forward triage has the potential to reduce exposures while conserving healthcare resources.},
  langid = {english},
  pmcid = {PMC8282595},
  pmid = {34274883},
  keywords = {Adolescent,Adult,Coronavirus,COVID-19,Female,Forward triage,Humans,Male,Middle Aged,Pandemic,Pandemics,Patient Satisfaction,SARS-CoV-2,Telehealth,Telemedicine,Triage,Young Adult},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\EHD4G8FZ\\Gupta et al. - 2021 - Telemedicine as a component of forward triage in a.pdf}
}

@article{gwet2008,
  title = {Computing Inter-Rater Reliability and Its Variance in the Presence of High Agreement},
  author = {Gwet, Kilem Li},
  year = {2008},
  month = may,
  journal = {Br J Math Stat Psychol},
  volume = {61},
  number = {Pt 1},
  pages = {29--48},
  issn = {0007-1102},
  doi = {10.1348/000711006X126600},
  abstract = {Pi (pi) and kappa (kappa) statistics are widely used in the areas of psychiatry and psychological testing to compute the extent of agreement between raters on nominally scaled data. It is a fact that these coefficients occasionally yield unexpected results in situations known as the paradoxes of kappa. This paper explores the origin of these limitations, and introduces an alternative and more stable agreement coefficient referred to as the AC1 coefficient. Also proposed are new variance estimators for the multiple-rater generalized pi and AC1 statistics, whose validity does not depend upon the hypothesis of independence between raters. This is an improvement over existing alternative variances, which depend on the independence assumption. A Monte-Carlo simulation study demonstrates the validity of these variance estimators for confidence interval construction, and confirms the value of AC1 as an improved alternative to existing inter-rater reliability statistics.},
  langid = {english},
  pmid = {18482474},
  keywords = {Analysis of Variance,Humans,Monte Carlo Method,Observer Variation,Probability,Psychological Tests,Psychometrics,Reproducibility of Results}
}

@article{gwet2015,
  title = {On {{Krippendorff}}'s {{Alpha Coefficient}}},
  author = {Gwet, Kilem L},
  year = {2015},
  pages = {16},
  abstract = {Krippendorff's alpha coefficient is a statistical measure of the extent of agreement among coders, and is regularly used by researchers in the field of content analysis. This coefficient is known to involve complex calculations, making the evaluation and its sampling variation possible only through resampling methods such as the bootstrap. In this paper, we propose a simple procedure for calculating Krippendorff's alpha that involves simple calculations similar to those needed to obtain the Pi coefficient of Fleiss (1971). We will propose a close expression for computing its variance, as well as a new interpretation based on the notion of weighting. Additionally, we will present some alternative agreement coefficients, which address the classical problem of the paradoxes associated with Cohen's Kappa, and described by Cicchetti and Feinstein (1990) and Feinstein and Cicchetti (1990).},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\2FM5CFYD\\Gwet - 2015 - On Krippendorff’s Alpha Coefficient.pdf}
}

@article{hallgren2012,
  title = {Computing {{Inter-Rater Reliability}} for {{Observational Data}}: {{An Overview}} and {{Tutorial}}},
  shorttitle = {Computing {{Inter-Rater Reliability}} for {{Observational Data}}},
  author = {Hallgren, Kevin A.},
  year = {2012},
  journal = {Tutor Quant Methods Psychol},
  volume = {8},
  number = {1},
  pages = {23--34},
  issn = {1913-4126},
  abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
  pmcid = {PMC3402032},
  pmid = {22833776},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\9YL9RIBW\\Hallgren - 2012 - Computing Inter-Rater Reliability for Observationa.pdf}
}

@article{hautz2021,
  title = {Online Forward Triage during the {{COVID-19}} Outbreak},
  author = {Hautz, Wolf E. and Exadaktylos, Aristomenis and Sauter, Thomas C.},
  year = {2021},
  month = feb,
  journal = {Emerg Med J},
  volume = {38},
  number = {2},
  pages = {106--108},
  issn = {1472-0213},
  doi = {10.1136/emermed-2020-209792},
  abstract = {Health systems face major challenges during the COVID-19 pandemic with new information and challenges emerging daily and frequently changing guidelines. Online forward triage tools (OFTTs) provide useful information, direct patients and free physician resources.We implemented an OFTT targeted at the current pandemic, adapted the content and goals and assessed its effects. The OFTT was implemented on 2 March 2020 and modified regularly based on the revised testing criteria issued by the Swiss Federal Office of Public Health. After testing criteria liberalised, a chatbot tool was set up on 9 April 2020 to assess urgency of testing, referral to available testing sites and need for emergency care.In the first 40 days of the OFTT, there were more than 17\,300 visitors and 69.8\% indicated they would have contacted the healthcare system if the online test had not been available. During the initial week of operation, using the conservative testing strategy, 9.1\% of visitors received recommendations to be tested, which increased to 36.0\% of visitors after a change in testing criteria on 9 March 2020. Overall, since the implementation of the tool, 26.27\% of all users of the site have been directed to obtain testing. The Chatbot tool has had approximately 50 consults/day.Setting up an OFTT should be considered as part of local strategies to cope with the COVID-19 pandemic. It may ease the burden on the healthcare system, reassure patients and inform authorities. To account for the dynamic development of the pandemic, frequent adaptation of the tool is of great importance. Further research on clinical outcomes of OFTT is urgently needed.},
  langid = {english},
  pmcid = {PMC7735070},
  pmid = {33310732},
  keywords = {clinical management,COVID-19,efficiency,emergency department utilisation,Humans,Internet,management,Mass Screening,Pandemics,Referral and Consultation,risk management,Switzerland,Triage},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\PXR72UMZ\\Hautz et al. - 2021 - Online forward triage during the COVID-19 outbreak.pdf}
}

@misc{hayes2018,
  title = {Alex Hayes - Predictive Performance via Bootstrap Variants},
  author = {Hayes, Alex},
  year = {2018},
  month = may,
  howpublished = {https://www.alexpghayes.com/post/2018-05-03\_performance-assessments-via-bootstrap-variants/},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\43VXTXG7\\2018-05-03_performance-assessments-via-bootstrap-variants.html}
}

@article{iwasaki2020,
  title = {Rapid Influenza Diagnostic Test at Triage Can Decrease Emergency Department Length of Stay},
  author = {Iwasaki, Tsutomu and Hifumi, Toru and Hayashi, Kuniyoshi and Otani, Norio and Ishimatsu, Shinichi},
  year = {2020},
  month = aug,
  journal = {J Am Coll Emerg Physicians Open},
  volume = {1},
  number = {4},
  pages = {494--501},
  issn = {2688-1152},
  doi = {10.1002/emp2.12125},
  abstract = {OBJECTIVE: Even if performing rapid influenza diagnostic tests test will not change clinical decision making, we sometimes perform at triage to reduce length of stay in Japan. Whether performing rapid influenza diagnostic tests at triage may shorten emergency department (ED) length of stay (LOS) is remains unclear. We aimed to determine the utility of rapid influenza diagnostic tests at triage in shortening ED length of stay LOS. METHODS: We retrospectively reviewed medical records of patients discharged from our ED after receiving results from rapid influenza diagnostic tests during the influenza season from December, 2013 to March, 2019. Eligibility criteria were a walk-in visit, age {$\geq$}15 years, triage performed, rapid influenza diagnostic test administered, and no admission. The triage group received rapid influenza diagnostic tests at triage. The after-examination group received their tests only after examination by a doctor. The primary outcome was ED LOS after propensity score matching to adjust for several covariates. RESULTS: Of 2,768 eligible patients, 2,554 patients were enrolled in the triage group (n = 363) or after examination group (n = 2,191). There were 329 matched pairs after propensity score matching. Median ED LOS was significantly shorter in the triage group than in the after-examination group after propensity score matching (81 min (interquartile range [IQR] 60 to 111) vs 106 min (IQR 80-142); median difference 24 min (95\% confidence interval 17-30)). CONCLUSIONS: Performing rapid influenza diagnostic tests at triage was associated with shorter ED LOS during the influenza season.},
  langid = {english},
  pmcid = {PMC7493520},
  pmid = {33000076},
  keywords = {crowding,emergency department,influenza,length of stay,point‐of‐care testing,propensity score,triage},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\LPTK8E8B\\Iwasaki et al. - 2020 - Rapid influenza diagnostic test at triage can decr.pdf}
}

@article{kain2019,
  title = {Preparing Intensive Care for the next Pandemic Influenza},
  author = {Kain, Taylor and Fowler, Robert},
  year = {2019},
  month = oct,
  journal = {Crit Care},
  volume = {23},
  number = {1},
  pages = {337},
  issn = {1466-609X},
  doi = {10.1186/s13054-019-2616-1},
  abstract = {Few viruses have shaped the course of human history more than influenza viruses. A century since the 1918-1919 Spanish influenza pandemic-the largest and deadliest influenza pandemic in recorded history-we have learned much about pandemic influenza and the origins of antigenic drift among influenza A viruses. Despite this knowledge, we remain largely underprepared for when the next major pandemic occurs.While emergency departments are likely to care for the first cases of pandemic influenza, intensive care units (ICUs) will certainly see the sickest and will likely have the most complex issues regarding resource allocation. Intensivists must therefore be prepared for the next pandemic influenza virus. Preparation requires multiple steps, including careful surveillance for new pandemics, a scalable response system to respond to surge capacity, vaccine production mechanisms, coordinated communication strategies, and stream-lined research plans for timely initiation during a pandemic. Conservative models of a large-scale influenza pandemic predict more than 170\% utilization of ICU-level resources. When faced with pandemic influenza, ICUs must have a strategy for resource allocation as strain increases on the system.There are several current threats, including avian influenza A(H5N1) and A(H7N9) viruses. As humans continue to live in closer proximity to each other, travel more extensively, and interact with greater numbers of birds and livestock, the risk of emergence of the next pandemic influenza virus mounts. Now is the time to prepare and coordinate local, national, and global efforts.},
  langid = {english},
  pmcid = {PMC6819413},
  pmid = {31665057},
  keywords = {Civil Defense,Critical Care,Disease Outbreaks,Health care worker safety,Highly pathogenic avian influenza,Human,Humans,Influenza,Influenza A Virus; H5N1 Subtype,Influenza A Virus; H7N9 Subtype,Influenza; Human,Intensive care,Pandemic,Pandemics,Preparation,Research,Resource allocation,Triage},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\U9SVHIYK\\Kain and Fowler - 2019 - Preparing intensive care for the next pandemic inf.pdf}
}

@article{katayama2020,
  title = {The Relationship between Seasonal Influenza and Telephone Triage for Fever: {{A}} Population-Based Study in {{Osaka}}, {{Japan}}},
  shorttitle = {The Relationship between Seasonal Influenza and Telephone Triage for Fever},
  author = {Katayama, Yusuke and Kiyohara, Kosuke and Komukai, Sho and Kitamura, Tetsuhisa and Ishida, Kenichiro and Hirose, Tomoya and Matsuyama, Tasuku and Kiguchi, Takeyuki and Hirayama, Atsushi and Shimazu, Takeshi},
  year = {2020},
  journal = {PLoS One},
  volume = {15},
  number = {8},
  pages = {e0236560},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0236560},
  abstract = {BACKGROUND: Replacing traditional surveillance with syndromic surveillance is one of the major interests in public health. However, it is unclear whether the number of influenza patients is associated with the number of telephone triages in Japan. METHODS: This retrospective, observational study was conducted over the six-year period between January 2012 to December 2017. We used the dataset of a telephone triage service in Osaka, Japan and the data on influenza patients published from the Information Center of Infectious Disease in Osaka prefecture. Using a linear regression model, we calculated Spearman's rank-order coefficient and R2 of the regression model to assess the relationship between the number of telephone triages for fever and the number of influenza patients in Osaka. Furthermore, we calculated Spearman's rank-order coefficient and R2 between the predicted weekly number of influenza patients from the linear regression model and the actual weekly number of influenza patients for influenza outbreak season (December-April). RESULTS: There were 465,971 patients with influenza, and the number of telephone triages for fever was 420,928 among 1,065,628 total telephone triages during the study period. Our analysis showed that the Spearman rank-order coefficient was 0.932, and R2 and adjusted R2 were 0.869 and 0.842, respectively. The Spearman rank-order coefficient was 0.923 (P{$<$}0.001) and R2 was 0.832 in December-April (P{$<$}0.001). CONCLUSION: We revealed a positive relationship in this population between the number of influenza patients and the number of telephone triages for fever.},
  langid = {english},
  pmcid = {PMC7410252},
  pmid = {32760164},
  keywords = {Adolescent,Adult,Aged,Aged; 80 and over,Child,Child; Preschool,Datasets as Topic,Disease Outbreaks,Female,Humans,Infant,Infant; Newborn,Influenza; Human,Information Centers,Japan,Male,Middle Aged,Population Surveillance,Retrospective Studies,Seasons,Sentinel Surveillance,Telemedicine,Triage,Young Adult},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\PYULS8I6\\Katayama et al. - 2020 - The relationship between seasonal influenza and te.pdf}
}

@article{kline2021,
  title = {Clinical Prediction Rule for {{SARS-CoV-2}} Infection from 116 {{U}}.{{S}}. Emergency Departments 2-22-2021},
  author = {Kline, Jeffrey A. and Camargo, Carlos A. and Courtney, D. Mark and Kabrhel, Christopher and Nordenholz, Kristen E. and Aufderheide, Thomas and Baugh, Joshua J. and Beiser, David G. and Bennett, Christopher L. and Bledsoe, Joseph and Castillo, Edward and {Chisolm-Straker}, Makini and Goldberg, Elizabeth M. and House, Hans and House, Stacey and Jang, Timothy and Lim, Stephen C. and Madsen, Troy E. and McCarthy, Danielle M. and Meltzer, Andrew and Moore, Stephen and Newgard, Craig and Pagenhardt, Justine and Pettit, Katherine L. and Pulia, Michael S. and Puskarich, Michael A. and Southerland, Lauren T. and Sparks, Scott and {Turner-Lawrence}, Danielle and Vrablik, Marie and Wang, Alfred and Weekes, Anthony J. and Westafer, Lauren and Wilburn, John},
  editor = {Kalendar, Ruslan},
  year = {2021},
  month = mar,
  journal = {PLoS ONE},
  volume = {16},
  number = {3},
  pages = {e0248438},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0248438},
  abstract = {Objectives Accurate and reliable criteria to rapidly estimate the probability of infection with the novel coronavirus-2 that causes the severe acute respiratory syndrome (SARS-CoV-2) and associated disease (COVID-19) remain an urgent unmet need, especially in emergency care. The objective was to derive and validate a clinical prediction score for SARS-CoV-2 infection that uses simple criteria widely available at the point of care. Methods Data came from the registry data from the national REgistry of suspected COVID-19 in EmeRgency care (RECOVER network) comprising 116 hospitals from 25 states in the US. Clinical variables and 30-day outcomes were abstracted from medical records of 19,850 emergency department (ED) patients tested for SARS-CoV-2. The criterion standard for diagnosis of SARS-CoV-2 required a positive molecular test from a swabbed sample or positive antibody testing within 30 days. The prediction score was derived from a 50\% random sample (n = 9,925) using unadjusted analysis of 107 candidate variables as a screening step, followed by stepwise forward logistic regression on 72 variables. Results Multivariable regression yielded a 13-variable score, which was simplified to a 13-point score: +1 point each for age{$>$}50 years, measured temperature{$>$}37.5\r{}C, oxygen saturation{$<$}95\%, Black race, Hispanic or Latino ethnicity, household contact with known or suspected COVID-19, patient reported history of dry cough, anosmia/dysgeusia, myalgias or fever; and -1 point each for White race, no direct contact with infected person, or smoking. In the validation sample (n = 9,975), the probability from logistic regression score produced an area under the receiver operating characteristic curve of 0.80 (95\% CI: 0.79\textendash 0.81), and this level of accuracy was retained across patients enrolled from the early spring to summer of 2020. In the simplified score, a score of zero produced a sensitivity of 95.6\% (94.8\textendash 96.3\%), specificity of 20.0\% (19.0\textendash 21.0\%), negative likelihood ratio of 0.22 (0.19\textendash 0.26). Increasing points on the simplified score predicted higher probability of infection (e.g., {$>$}75\% probability with +5 or more points). Conclusion Criteria that are available at the point of care can accurately predict the probability of SARSCoV-2 infection. These criteria could assist with decisions about isolation and testing at high throughput checkpoints.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\BMG8LLIH\\Kline et al. - 2021 - Clinical prediction rule for SARS-CoV-2 infection .pdf}
}

@article{koo2016,
  title = {A {{Guideline}} of {{Selecting}} and {{Reporting Intraclass Correlation Coefficients}} for {{Reliability Research}}},
  author = {Koo, Terry K. and Li, Mae Y.},
  year = {2016},
  month = jun,
  journal = {J Chiropr Med},
  volume = {15},
  number = {2},
  pages = {155--163},
  issn = {1556-3707},
  doi = {10.1016/j.jcm.2016.02.012},
  abstract = {OBJECTIVE: Intraclass correlation coefficient (ICC) is a widely used reliability index in test-retest, intrarater, and interrater reliability analyses. This article introduces the basic concept of ICC in the content of reliability analysis. DISCUSSION FOR RESEARCHERS: There are 10 forms of ICCs. Because each form involves distinct assumptions in their calculation and will lead to different interpretations, researchers should explicitly specify the ICC form they used in their calculation. A thorough review of the research design is needed in selecting the appropriate form of ICC to evaluate reliability. The best practice of reporting ICC should include software information, "model," "type," and "definition" selections. DISCUSSION FOR READERS: When coming across an article that includes ICC, readers should first check whether information about the ICC form has been reported and if an appropriate ICC form was used. Based on the 95\% confident interval of the ICC estimate, values less than 0.5, between 0.5 and 0.75, between 0.75 and 0.9, and greater than 0.90 are indicative of poor, moderate, good, and excellent reliability, respectively. CONCLUSION: This article provides a practical guideline for clinical researchers to choose the correct form of ICC and suggests the best practice of reporting ICC parameters in scientific publications. This article also gives readers an appreciation for what to look for when coming across ICC while reading an article.},
  langid = {english},
  pmcid = {PMC4913118},
  pmid = {27330520},
  keywords = {Reliability and validity,Research,Statistics},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\LVY8SZFR\\Koo and Li - 2016 - A Guideline of Selecting and Reporting Intraclass .pdf}
}

@article{lucero-obusan2017,
  title = {Enhanced {{Influenza Surveillance Using Telephone Triage}} and {{Electronic Syndromic Surveillance}} in the {{Department}} of {{Veterans Affairs}}, 2011-2015},
  author = {{Lucero-Obusan}, Cynthia and Winston, Carla A. and Schirmer, Patricia L. and Oda, Gina and Holodniy, Mark},
  year = {2017 Jul/Aug},
  journal = {Public Health Rep},
  volume = {132},
  number = {1\_suppl},
  pages = {16S-22S},
  issn = {1468-2877},
  doi = {10.1177/0033354917709779},
  abstract = {Telephone triage (TT) is a method whereby medical professionals speak by telephone to patients to assess their symptoms or health concerns and offer advice. These services are often administered through an electronic TT system, which guides TT professionals during the encounter through the use of structured protocols and algorithms to help determine the severity of the patients' health issue and refer them to appropriate care. TT is also an emerging data source for public health surveillance of infectious and noninfectious diseases, including influenza. We calculated Spearman correlation coefficients to compare the weekly number of US Department of Veterans Affairs (VA) TT calls with other conventional influenza measures for the 2011-2012 through 2014-2015 influenza seasons, for which there were a total of 35\,666 influenza-coded TT encounters. Influenza-coded calls were strongly correlated with weekly VA influenza-coded hospitalizations (0.85), emergency department visits (0.90), influenza-like illness outpatient visits (0.92), influenza tests performed (0.86), positive influenza tests (0.82), and influenza antiviral prescriptions (0.89). The correlation between VA-TT and Centers for Disease Control and Prevention (CDC) national data for weekly influenza hospitalizations, influenza tests performed, and positive influenza tests was also strong. TT correlates well with VA health care use and CDC data and is a timely data source for monitoring influenza activity.},
  langid = {english},
  pmcid = {PMC5676515},
  pmid = {28692402},
  keywords = {Disease Outbreaks,Humans,influenza surveillance,Influenza; Human,Population Surveillance,Telephone,telephone triage,Triage,United States,United States Department of Veterans Affairs,veterans,Veterans},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\VIZZTGLN\\Lucero-Obusan et al. - 2017 - Enhanced Influenza Surveillance Using Telephone Tr.pdf}
}

@article{lyon2020,
  title = {Diagnostic Accuracy of an App-Guided, Self-Administered Test for Influenza among Individuals Presenting to General Practice with Influenza-like Illness: Study Protocol},
  shorttitle = {Diagnostic Accuracy of an App-Guided, Self-Administered Test for Influenza among Individuals Presenting to General Practice with Influenza-like Illness},
  author = {Lyon, Victoria and Zigman Suchsland, Monica and Chilver, Monique and Stocks, Nigel and Lutz, Barry and Su, Philip and Cooper, Shawna and Park, Chunjong and Lavitt, Libby Rose and Mariakakis, Alex and Patel, Shwetak and Graham, Chelsey and Rieder, Mark and LeRouge, Cynthia and Thompson, Matthew},
  year = {2020},
  month = nov,
  journal = {BMJ Open},
  volume = {10},
  number = {11},
  pages = {e036298},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2019-036298},
  abstract = {Introduction\hspace{0.6em} Diagnostic tests for influenza in Australia are currently only authorised for use in clinical settings. At-\-home diagnostic testing for influenza could reduce the need for patient contact with healthcare services, which potentially could contribute to symptomatic improvement and reduced spread of influenza. We aim to determine the accuracy of an app-\-guided nasal self-\-swab combined with a lateral flow immunoassay for influenza conducted by individuals with influenza-\-like illness (ILI). Methods and analysis\hspace{0.6em} Adults ({$\geq$}18\,years) presenting with ILI will be recruited by general practitioners (GP) participating in Australian Sentinel Practices Research Network. Eligible participants will have a nasal swab obtained by their GP for verification of influenza A/B status using reverse transcription polymerase chain reaction (RT-\-PCR) test at an accredited laboratory. Participants will receive an influenza test kit and will download an app that collects self-\-reported symptoms and influenza risk factors, then instructs them in obtaining a low-\-nasal self-\-swab, running a QuickVue influenza A+B lateral flow immunoassay (Quidel Corporation) and interpreting the results. Participants will also interpret an enhanced image of the test strip in the app. The primary outcome will be the accuracy of participants' test interpretation compared with the laboratory RT-\-PCR reference standard. Secondary analyses will include accuracy of the enhanced test strip image, accuracy of an automatic test strip reader algorithm and validation of prediction rules for influenza based on self-\-reported symptoms. A post-\-test survey will be used to obtain participant feedback on self-\-test procedures. Ethics and dissemination\hspace{0.6em} The study was approved by the Human Research and Ethic Committee (HREC) at the University of Adelaide (H-2019-116). Protocol details and any amendments will be reported to https://www.tga. gov.au/. Results will be published in the peer-\-reviewed literature, and shared with stakeholders in the primary care and diagnostics communities.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\N9RIYQJX\\Lyon et al. - 2020 - Diagnostic accuracy of an app-guided, self-adminis.pdf}
}

@article{mccoul2019,
  title = {Differences in the {{Intended Meaning}} of {{Congestion Between Patients}} and {{Clinicians}}},
  author = {McCoul, Edward D. and Mohammed, Alaa E. and Debbaneh, Peter M. and Carratola, Maria and Patel, Amit S.},
  year = {2019},
  month = jul,
  journal = {JAMA Otolaryngology\textendash Head \& Neck Surgery},
  volume = {145},
  number = {7},
  pages = {634--640},
  issn = {2168-6181},
  doi = {10.1001/jamaoto.2019.1023},
  abstract = {Disagreement in the presumed meaning of common medical terms may impair communication between patients and caregivers.To clarify the intended meaning of the term congestion among otolaryngology clinic patients and to identify discrepancies in definitions between patients and otolaryngologists.In this cross-sectional survey study from an otolaryngology clinic at an academic center, a semantics-based questionnaire was provided to consecutive new patients during intake for a clinical encounter from December 2016 through February 2017, and to 31 otolaryngologists and 28 nonotolaryngologist physicians in February 2018. Respondent definitions for congestion were selected from a list of 16 proposed terms covering 4 general categories.Symptom categories for term used to describe congestion by patients and clinicians.Among 226 patient respondents (133 female [58.8\%]; mean [SD] age, 54 [15.6] years), the most commonly selected definitions for congestion were from the obstructive (199; 88.1\%) and mucus-related (196; 86.7\%) symptom categories. More than 1 general category was selected by 208 patients (92.0\%), whereas 11 patients (4.9\%) described congestion only in terms of mucus-related symptoms. Definitions were limited to upper respiratory tract symptoms by 83 (36.7\%) patients and lower respiratory tract symptoms by 2 (0.9\%) patients. Among 31 otolaryngologists, congestion was most frequently defined in terms of obstructive symptoms (difference, 11.9\%; 95\% CI, 7.4\%-16.5\%). In contrast, patients more often described congestion in terms of pressure-related (difference, 38.8\%; 95\% CI, 7.5\%-70.1\%) or mucus-related (difference, 51.2\%; 95\% CI, 22.6\%-79.9\%) symptoms. A total of 22 otolaryngologists (71.0\%) defined congestion using 1 to 4 symptoms, compared with only 69 patients (30.5\%).The definition of congestion appears to be highly variable and ambiguous for many patients. Moreover, the findings suggest that patients and otolaryngologists generally do not describe congestion using the same terms.},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\TLZFDNLE\\McCoul et al. - 2019 - Differences in the Intended Meaning of Congestion .pdf;C\:\\Users\\Zane\\Zotero\\storage\\KYGHMW7E\\2734874.html}
}

@article{mcgough2009,
  title = {Estimating the {{Size}} of {{Treatment Effects}}},
  author = {McGough, James J. and Faraone, Stephen V.},
  year = {2009},
  month = oct,
  journal = {Psychiatry (Edgmont)},
  volume = {6},
  number = {10},
  pages = {21--29},
  issn = {1550-5952},
  abstract = {Objective: To increase understanding of effect size calculations among clinicians who over-rely on interpretations of P values in their assessment of the medical literature., Design: We review five methods of calculating effect sizes: Cohen's d (also known as the standardized mean difference)\textemdash used in studies that report efficacy in terms of a continuous measurement and calculated from two mean values and their standard deviations; relative risk\textemdash the ratio of patients responding to treatment divided by the ratio of patients responding to a different treatment (or placebo), which is particularly useful in prospective clinical trials to assess differences between treatments; odds ratio\textemdash{} used to interpret results of retrospective case-control studies and provide estimates of the risk of side effects by comparing the probability (odds) of an outcome occurring in the presence or absence of a specified condition; number needed to treat\textemdash the number of subjects one would expect to treat with agent A to have one more success (or one less failure) than if the same number were treated with agent B; and area under the curve (also known as the drug-placebo response curve)\textemdash a six-step process that can be used to assess the effects of medication on both worsening and improvement and the probability that a medication-treated subject will have a better outcome than a placebo-treated subject., Conclusion: Effect size statistics provide a better estimate of treatment effects than P values alone.},
  pmcid = {PMC2791668},
  pmid = {20011465},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\Y44934P2\\McGough and Faraone - 2009 - Estimating the Size of Treatment Effects.pdf}
}

@article{mchugh2012,
  title = {Interrater Reliability: The Kappa Statistic},
  shorttitle = {Interrater Reliability},
  author = {McHugh, Mary L.},
  year = {2012},
  month = oct,
  journal = {Biochem Med (Zagreb)},
  volume = {22},
  number = {3},
  pages = {276--282},
  issn = {1330-0962},
  abstract = {The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen's kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen's suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.},
  pmcid = {PMC3900052},
  pmid = {23092060},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\8E7VB5GB\\McHugh - 2012 - Interrater reliability the kappa statistic.pdf}
}

@article{mckay2020,
  title = {Associations {{Between Relative Viral Load}} at {{Diagnosis}} and {{Influenza A Symptoms}} and {{Recovery}}},
  author = {McKay, Brian and Ebell, Mark and Billings, Wesley Zane and Dale, Ariella Perry and Shen, Ye and Handel, Andreas},
  year = {2020},
  month = oct,
  journal = {Open Forum Infect Dis},
  volume = {7},
  number = {11},
  pages = {ofaa494},
  issn = {2328-8957},
  doi = {10.1093/ofid/ofaa494},
  abstract = {Rapid point-of-care (POC) PCR tests can generate estimates of viral load. Viral loads at diagnosis using a POC PCR test are associated with body temperature. Among our population, viral load at diagnosis was not predictive of disease severity or recovery.},
  pmcid = {PMC7751133},
  pmid = {33376754},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\VAA32JA5\\McKay et al. - 2020 - Associations Between Relative Viral Load at Diagno.pdf}
}

@article{mckay2020a,
  title = {Virulence-Mediated Infectiousness and Activity Trade-Offs and Their Impact on Transmission Potential of Influenza Patients},
  author = {McKay, Brian and Ebell, Mark and Dale, Ariella Perry and Shen, Ye and Handel, Andreas},
  year = {2020},
  month = may,
  journal = {Proc Biol Sci},
  volume = {287},
  number = {1927},
  pages = {20200496},
  issn = {1471-2954},
  doi = {10.1098/rspb.2020.0496},
  abstract = {Communicable diseases are often virulent, i.e. they cause morbidity symptoms in those infected. While some symptoms may be transmission-enhancing, other symptoms are likely to reduce transmission potential. For human diseases, the reduction in transmission opportunities is commonly caused by reduced activity. There is limited data regarding the potential impact of virulence on transmission potential. We performed an exploratory data analysis of 324 influenza patients at a university health centre during the 2016/2017 influenza season. We classified symptoms as infectiousness-related or morbidity-related and calculated two scores. The scores were used to explore the relationship between infectiousness, morbidity (virulence), and activity level. We found a decrease in the activity level with increasing morbidity scores. There was no consistent pattern between an activity level and an infectiousness score. We also found a positive correlation between morbidity and infectiousness scores. Overall, we find that increasing virulence leads to increased infectiousness and reduced activity, suggesting a trade-off that can impact overall transmission potential. Our findings indicate that a reduction of systemic symptoms may increase host activity without reducing infectiousness. Therefore, interventions should target both systemic- and infectiousness-related symptoms to reduce overall transmission potential. Our findings can also inform simulation models that investigate the impact of different interventions on transmission.},
  langid = {english},
  pmcid = {PMC7287351},
  pmid = {32396798},
  keywords = {Humans,infectious diseases,influenza,Influenza; Human,trade-off,transmission,virulence,Virulence},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\RNE3REX8\\McKay et al. - 2020 - Virulence-mediated infectiousness and activity tra.pdf;C\:\\Users\\Zane\\Zotero\\storage\\UGD8C5Q7\\rspb20200496_si_001.pdf}
}

@article{merckx2017,
  title = {Diagnostic {{Accuracy}} of {{Novel}} and {{Traditional Rapid Tests}} for {{Influenza Infection Compared With Reverse Transcriptase Polymerase Chain Reaction}}: {{A Systematic Review}} and {{Meta-analysis}}},
  shorttitle = {Diagnostic {{Accuracy}} of {{Novel}} and {{Traditional Rapid Tests}} for {{Influenza Infection Compared With Reverse Transcriptase Polymerase Chain Reaction}}},
  author = {Merckx, Joanna and Wali, Rehab and Schiller, Ian and Caya, Chelsea and Gore, Genevieve C. and Chartrand, Caroline and Dendukuri, Nandini and Papenburg, Jesse},
  year = {2017},
  month = sep,
  journal = {Ann Intern Med},
  volume = {167},
  number = {6},
  pages = {394--409},
  issn = {1539-3704},
  doi = {10.7326/M17-0848},
  abstract = {BACKGROUND: Rapid and accurate influenza diagnostics can improve patient care. PURPOSE: To summarize and compare accuracy of traditional rapid influenza diagnostic tests (RIDTs), digital immunoassays (DIAs), and rapid nucleic acid amplification tests (NAATs) in children and adults with suspected influenza. DATA SOURCES: 6 databases from their inception through May 2017. STUDY SELECTION: Studies in English, French, or Spanish comparing commercialized rapid tests (that is, providing results in {$<$}30 minutes) with reverse transcriptase polymerase chain reaction reference standard for influenza diagnosis. DATA EXTRACTION: Data were extracted using a standardized form; quality was assessed using QUADAS-2 (Quality Assessment of Diagnostic Accuracy Studies 2) criteria. DATA SYNTHESIS: 162 studies were included (130 of RIDTs, 19 of DIAs, and 13 of NAATs). Pooled sensitivities for detecting influenza A from Bayesian bivariate random-effects models were 54.4\% (95\% credible interval [CrI], 48.9\% to 59.8\%) for RIDTs, 80.0\% (CrI, 73.4\% to 85.6\%) for DIAs, and 91.6\% (CrI, 84.9\% to 95.9\%) for NAATs. Those for detecting influenza B were 53.2\% (CrI, 41.7\% to 64.4\%) for RIDTs, 76.8\% (CrI, 65.4\% to 85.4\%) for DIAs, and 95.4\% (CrI, 87.3\% to 98.7\%) for NAATs. Pooled specificities were uniformly high ({$>$}98\%). Forty-six influenza A and 24 influenza B studies presented pediatric-specific data; 35 influenza A and 16 influenza B studies presented adult-specific data. Pooled sensitivities were higher in children by 12.1 to 31.8 percentage points, except for influenza A by rapid NAATs (2.7 percentage points). Pooled sensitivities favored industry-sponsored studies by 6.2 to 34.0 percentage points. Incomplete reporting frequently led to unclear risk of bias. LIMITATIONS: Underreporting of clinical variables limited exploration of heterogeneity. Few NAAT studies reported adult-specific data, and none evaluated point-of-care testing. Many studies had unclear risk of bias. CONCLUSION: Novel DIAs and rapid NAATs had markedly higher sensitivities for influenza A and B in both children and adults than did traditional RIDTs, with equally high specificities. PRIMARY FUNDING SOURCE: Qu\'ebec Health Research Fund and BD Diagnostic Systems.},
  langid = {english},
  pmid = {28869986},
  keywords = {Adult,Child,Diagnostic Tests; Routine,Humans,Immunoassay,Influenza; Human,Molecular Diagnostic Techniques,Reverse Transcriptase Polymerase Chain Reaction}
}

@article{minozzi2022,
  title = {Kappa and {{AC1}}/2 Statistics: Beyond the Paradox},
  shorttitle = {Kappa and {{AC1}}/2 Statistics},
  author = {Minozzi, Silvia and Cinquini, Michela and Gianola, Silvia and {Gonzalez-Lorenzo}, Marien and Banzi, Rita},
  year = {2022},
  month = feb,
  journal = {J Clin Epidemiol},
  volume = {142},
  pages = {328--329},
  issn = {1878-5921},
  doi = {10.1016/j.jclinepi.2021.09.004},
  langid = {english},
  pmid = {34520848},
  keywords = {Humans,Reproducibility of Results},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\X56KRFLD\\Minozzi et al. - 2022 - Kappa and AC12 statistics beyond the paradox.pdf}
}

@article{monto2000,
  title = {Clinical Signs and Symptoms Predicting Influenza Infection},
  author = {Monto, A. S. and Gravenstein, S. and Elliott, M. and Colopy, M. and Schweinle, J.},
  year = {2000},
  month = nov,
  journal = {Arch Intern Med},
  volume = {160},
  number = {21},
  pages = {3243--3247},
  issn = {0003-9926},
  doi = {10.1001/archinte.160.21.3243},
  abstract = {BACKGROUND: New antiviral drugs are available for the treatment of influenza type A and type B infections. In clinical practice, antiviral use has rarely been guided by antecedent laboratory diagnosis. Defined clinical predictors of an influenza infection can help guide timely therapy and avoid unnecessary antibiotic use. OBJECTIVE: To examine which clinical signs and symptoms are most predictive of influenza infection in patients with influenza-like illness using a large data set derived from clinical trials of zanamivir. METHODS: This analysis is a retrospective, pooled analysis of baseline signs and symptoms from phase 2 and 3 clinical trial participants. It was conducted in mainly unvaccinated (mean age, 35 years) adults and adolescents who had influenza-like illness, defined as having fever or feverishness plus at least 2 of the following influenza-like symptoms: headache, myalgia, cough, or sore throat who underwent laboratory testing for influenza. Clinical signs and symptoms were evaluated in statistical models to identify those best predicting laboratory confirmation of influenza. RESULTS: Of 3744 subjects enrolled with baseline influenza-like symptoms, and included in this analysis, 2470 (66\%) were confirmed to have influenza. Individuals with influenza were more likely to have cough (93\% vs 80\%), fever (68\% vs 40\%), cough and fever together (64\% vs 33\%), and/or nasal congestion (91\% vs 81\%) than those without influenza. The best multivariate predictors of influenza infections were cough and fever with a positive predictive value of 79\% (P{$<$}. 001). The positive predictive value rose with the increase in the temperature at the time of recruitment. CONCLUSION: When influenza is circulating within the community, patients with an influenza-like illness who have both cough and fever within 48 hours of symptom onset are likely to have influenza and the administration of influenza antiviral therapy may be appropriate to consider. Arch Intern Med. 2000;160:3243-3247.},
  langid = {english},
  pmid = {11088084},
  keywords = {Adolescent,Adult,Antiviral Agents,Clinical Trials; Phase II as Topic,Clinical Trials; Phase III as Topic,Cough,Diagnosis; Differential,Double-Blind Method,Female,Fever,Guanidines,Humans,Influenza; Human,Male,Middle Aged,Multicenter Studies as Topic,Multivariate Analysis,Pharyngitis,Predictive Value of Tests,Pyrans,Retrospective Studies,Sialic Acids,Time Factors,Zanamivir},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\5VW88LK7\\Monto et al. - 2000 - Clinical signs and symptoms predicting influenza i.pdf}
}

@article{nevel2021,
  title = {Inter-rater Reliability and Prospective Validation of a Clinical Prediction Rule for {{SARS}}-{{CoV}}-2 Infection},
  author = {Nevel, Adam E. and Kline, Jeffrey A.},
  year = {2021},
  month = jul,
  journal = {Acad Emerg Med},
  volume = {28},
  number = {7},
  pages = {761--767},
  issn = {1069-6563, 1553-2712},
  doi = {10.1111/acem.14309},
  abstract = {Objectives: Accurate estimation of the risk of SARS-\-CoV-\-2 infection based on bedside data alone has importance to emergency department (ED) operations and throughput. The 13-\-item CORC (COVID [or coronavirus] Rule-\-out Criteria) rule had good overall diagnostic accuracy in retrospective derivation and validation. The objective of this study was to prospectively test the inter-\-rater reliability and diagnostic accuracy of the CORC score and rule (score {$\leq$} 0 negative, {$>$} 0 positive) and compare the CORC rule performance with physician gestalt. Methods: This noninterventional study was conducted at an urban academic ED from February 2021 to March 2021. Two practitioners were approached by research coordinators and asked to independently complete a form capturing the CORC criteria for their shared patient and their gestalt binary prediction of the SARS-\-CoV-\-2 test result and confidence (0\%\textendash\-100\%). The criterion standard for SARS-\-CoV-\-2 was from reverse transcriptase polymerase chain reaction performed on a nasopharyngeal swab. The primary analysis was from weighted Cohen's kappa and likelihood ratios (LRs). Results: For 928 patients, agreement between observers was good for the total CORC score, {$\kappa$} = 0.613 (95\% confidence interval [CI] = 0.579\textendash\-0.646), and for the CORC rule, {$\kappa$} = 0.644 (95\% CI = 0.591\textendash\-0.697). The agreement for clinician gestalt binary determination of SARs-\-CoV-\-2 status was {$\kappa$} = 0.534 (95\% CI = 0.437\textendash\-0.632) with median confidence of 76\% (first\textendash\-third quartile = 66\textendash\-88.5). For 425 patients who had the criterion standard, a negative CORC rule (both observers scored CORC {$<$} 0), the sensitivity was 88\%, and specificity was 51\%, with a negative LR (LR-) of 0.24 (95\% CI = 0.10\textendash\-0.50). Among patients with a mean CORC score of {$>$}4, the prevalence of a positive SARS-\- CoV-\-2 test was 58\% (95\% CI = 28\%\textendash\-85\%) and positive LR was 13.1 (95\% CI = 4.5\textendash\- 37.2). Clinician gestalt demonstrated a sensitivity of 51\% and specificity of 86\% with a LR- of 0.57 (95\% CI = 0.39\textendash\-0.74). Conclusion: In this prospective study, the CORC score and rule demonstrated good inter-\-rater reliability and reproducible diagnostic accuracy for estimating the pretest probability of SARs-\-CoV-\-2 infection.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\Q6DS7FJ5\\Nevel and Kline - 2021 - Inter‐rater reliability and prospective validation.pdf}
}

@misc{pananos2021,
  title = {{{PhDemetri}} - {{Hacking Sklearn To Do The Optimism Corrected Bootstrap}}},
  author = {Pananos, Demetri},
  year = {2021},
  month = nov,
  howpublished = {https://dpananos.github.io/posts/2021-11-23-bootstrap/},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\LK4HKDXQ\\2021-11-23-bootstrap.html}
}

@article{pauker1980,
  title = {The {{Threshold Approach}} to {{Clinical Decision Making}}},
  author = {Pauker, Stephen G. and Kassirer, Jerome P.},
  year = {1980},
  month = may,
  journal = {New England Journal of Medicine},
  volume = {302},
  number = {20},
  pages = {1109--1117},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJM198005153022003},
  abstract = {WHEN two different approaches to managing a patient appear to have the same potential value, the decision faced by the physician is often described as a "toss-up." This concept of indifference between strategies is familiar to all experienced clinicians but has received scant attention as a possible reference point in clinical decision making. In a previous study we developed the concept of the therapeutic threshold \textemdash{} a probability of disease that constitutes one such point of indifference.1 In problems that can be reduced to two choices, i.e., either administering or withholding a specific treatment for a specific disease, this threshold . . .},
  pmid = {7366635},
  annotation = {\_eprint: https://doi.org/10.1056/NEJM198005153022003},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\GUGWDH93\\Pauker and Kassirer - 1980 - The Threshold Approach to Clinical Decision Making.pdf;C\:\\Users\\Zane\\Zotero\\storage\\HDEX6QVV\\NEJM198005153022003.html}
}

@misc{powers2020,
  title = {Evaluation: From Precision, Recall and {{F-measure}} to {{ROC}}, Informedness, Markedness and Correlation},
  shorttitle = {Evaluation},
  author = {Powers, David M. W.},
  year = {2020},
  month = oct,
  number = {arXiv:2010.16061},
  eprint = {2010.16061},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2010.16061},
  abstract = {Commonly used evaluation measures including Recall, Precision, F-Measure and Rand Accuracy are biased and should not be used without clear understanding of the biases, and corresponding identification of chance or base case levels of the statistic. Using these measures a system that performs worse in the objective sense of Informedness, can appear to perform better under any of these commonly used measures. We discuss several concepts and measures that reflect the probability that prediction is informed versus chance. Informedness and introduce Markedness as a dual measure for the probability that prediction is marked versus chance. Finally we demonstrate elegant connections between the concepts of Informedness, Markedness, Correlation and Significance as well as their intuitive relationships with Recall and Precision, and outline the extension from the dichotomous case to the general multi-class case.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\LKG48A4B\\Powers - 2020 - Evaluation from precision, recall and F-measure t.pdf;C\:\\Users\\Zane\\Zotero\\storage\\SJ9CWYL7\\2010.html}
}

@book{rms,
  title = {Regression {{Modeling Strategies}}: {{With Applications}} to {{Linear Models}}, {{Logistic}}, and {{Ordinal Regression}}, and {{Survival Analysis}}},
  author = {Harrell, Frank E.},
  year = {2015},
  series = {Springer {{Series}} in {{Statistics}}},
  edition = {Second},
  publisher = {{Springer International Publishing}},
  address = {{Switzerland}}
}

@article{rothberg2020,
  title = {Influenza {{Management}} via {{Direct}} to {{Consumer Telemedicine}}: An {{Observational Study}}},
  shorttitle = {Influenza {{Management}} via {{Direct}} to {{Consumer Telemedicine}}},
  author = {Rothberg, Michael B. and Martinez, Kathryn A.},
  year = {2020},
  month = oct,
  journal = {J Gen Intern Med},
  volume = {35},
  number = {10},
  pages = {3111--3113},
  issn = {0884-8734},
  doi = {10.1007/s11606-020-05640-5},
  pmcid = {PMC7573037},
  pmid = {31919730},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\PMIVTRX8\\Rothberg and Martinez - 2020 - Influenza Management via Direct to Consumer Teleme.pdf}
}

@article{sintchenko2002,
  title = {Treat or Test First? {{Decision}} Analysis of Empirical Antiviral Treatment of Influenza Virus Infection versus Treatment Based on Rapid Test Results},
  shorttitle = {Treat or Test First?},
  author = {Sintchenko, V and Gilbert, G. L and Coiera, E and Dwyer, D},
  year = {2002},
  month = jul,
  journal = {Journal of Clinical Virology},
  volume = {25},
  number = {1},
  pages = {15--21},
  issn = {1386-6532},
  doi = {10.1016/S1386-6532(00)00182-7},
  abstract = {Background: neuraminidase (NA) inhibitors have recently become available for treatment of influenza. Rapid antigen detection assays at `point-of-care' may improve the accuracy of clinical diagnosis, but the value of these techniques in assisting with the appropriate use of antivirals remains controversial. Objective: to compare the diagnostic utilities of two management strategies for influenza, empirical antiviral therapy versus therapy based on a positive rapid test result in pre-epidemic and epidemic periods. Study design: a threshold decision analytic model was designed to compare these competing strategies and sensitivity analysis performed to examine the impact of diagnostic variables on the expected utility of the decision with a range of prior probabilities of infection between 1 and 50\%. Results: on the basis of the calculated sensitivity (77\%) and specificity (95\%) of a point-of-care test for influenza, pre-treatment testing was preferred and cost-effective in non-epidemic stage of the influenza cycle. The alternative strategy of empirical treatment produces a higher utility value during epidemics, but may result in overuse of antivirals for low-risk populations. The two strategies had equivalent efficacy when the probability of influenza was 42\%. Conclusions: Patients with flu-like illness, who present outside the influenza outbreak and are considered to be at low risk for influenza-related complications, should be tested to confirm the diagnosis before starting antiviral treatment with a NA inhibitor. The most important variables in the model were the accuracy of the clinical diagnosis and the pre-test probability of influenza. A threshold probability of influenza of 42\% would dictate changing from the rapid testing strategy to a `treat regardless' strategy.},
  langid = {english},
  keywords = {Decision analysis,Influenza,Laboratory diagnosis,Treatment},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\YVFHINNK\\S1386653200001827.html}
}

@article{stevens2020,
  title = {Validation of Clinical Prediction Models: What Does the ``Calibration Slope'' Really Measure?},
  shorttitle = {Validation of Clinical Prediction Models},
  author = {Stevens, Richard J. and Poppe, Katrina K.},
  year = {2020},
  month = feb,
  journal = {Journal of Clinical Epidemiology},
  volume = {118},
  pages = {93--99},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2019.09.016},
  abstract = {Background and Objectives Definitions of calibration, an aspect of model validation, have evolved over time. We examine use and interpretation of the statistic currently referred to as the calibration slope. Methods The history of the term ``calibration slope'', and usage in papers published in 2016 and 2017, were reviewed. The behaviour of the slope in illustrative hypothetical examples and in two examples in the clinical literature was demonstrated. Results The paper in which the statistic was proposed described it as a measure of ``spread'' and did not use the term ``calibration''. In illustrative examples, slope of 1 can be associated with good or bad calibration, and this holds true across different definitions of calibration. In data extracted from a previous study, the slope was correlated with discrimination, not overall calibration. Many authors of recent papers interpret the slope as a measure of calibration; a minority interpret it as a measure of discrimination or do not explicitly categorise it as either. Seventeen of thirty-three papers used the slope as the sole measure of calibration. Conclusion Misunderstanding about this statistic has led to many papers in which it is the sole measure of calibration, which should be discouraged.},
  langid = {english},
  keywords = {Calibration,Clinical prediction rule,Discrimination,Slope,Spread,Validation},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\UPRCWANK\\Stevens and Poppe - 2020 - Validation of clinical prediction models what doe.pdf;C\:\\Users\\Zane\\Zotero\\storage\\CQQR9AGI\\S0895435619303579.html}
}

@article{trombetta2018,
  title = {Are {{Rapid Influenza Antigen Tests Still Clinically Useful}} in {{Today}}'s {{Molecular Diagnostics World}}?},
  author = {Trombetta, Valentina K and Chan, Yvonne L and Bankowski, Matthew J},
  year = {2018},
  month = sep,
  journal = {Hawaii J Med Public Health},
  volume = {77},
  number = {9},
  pages = {226--230},
  issn = {2165-8218},
  abstract = {Influenza virus infection and disease historically contribute to widespread cases of seasonal morbidity and in some cases mortality. Prompt and accurate diagnosis is crucial for optimal patient management. Rapid influenza direct antigen testing (RIDT) offers a faster turn-around-time for results but test performance (ie, sensitivity and specificity) varies widely. Nucleic acid amplification testing (NAAT) can offer a viable alternative. The objective of this retrospective study was to compare the test performance of RIDT with NAAT. RIDT testing included the Directigen EZ Flu A+B or the Veritor System for Rapid Detection of Flu A+B. NAAT employed the SimplexaTM Flu A/B\texttrademark{} RSV assay. A total of 5,795 specimens collected from October to March for the 2012/2013 (n=953), 2013/2014 (n=2060) and 2014/2015 (n=2783) seasons were co-tested by RIDT and NAAT. Using NAAT as the gold standard, RIDT tests had a sensitivity range of 0 to 15.7\% and a specificity of 98.2 to 100\% for influenza type A. For influenza type B, RIDT tests had a sensitivity of 0 to 33.3\% and a specificity of 98.9 to 100\%. These findings suggest that RIDT has unacceptably low sensitivity for both influenza A and influenza B, despite high specificity. The key advantage of RIDT in previous years (faster turnaround time) has been challenged by newer NAAT technology that provides results in a turn-around-time comparable to RIDT, but with superior test performance.},
  pmcid = {PMC6137576},
  pmid = {30221077},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\YINSIQWD\\Trombetta et al. - 2018 - Are Rapid Influenza Antigen Tests Still Clinically.pdf}
}

@article{vancalster2019,
  title = {Calibration: The {{Achilles}} Heel of Predictive Analytics},
  shorttitle = {Calibration},
  author = {Van Calster, Ben and McLernon, David J. and {van Smeden}, Maarten and Wynants, Laure and Steyerberg, Ewout W. and Bossuyt, Patrick and Collins, Gary S. and Macaskill, Petra and McLernon, David J. and Moons, Karel G. M. and Steyerberg, Ewout W. and Van~Calster, Ben and {van~Smeden}, Maarten and Vickers, Andrew~J. and {On behalf of Topic Group `Evaluating diagnostic tests and prediction models' of the STRATOS initiative}},
  year = {2019},
  month = dec,
  journal = {BMC Medicine},
  volume = {17},
  number = {1},
  pages = {230},
  issn = {1741-7015},
  doi = {10.1186/s12916-019-1466-7},
  abstract = {The assessment of calibration performance of risk prediction models based on regression or more flexible machine learning algorithms receives little attention.},
  keywords = {Calibration,Heterogeneity,Model performance,Overfitting,Predictive analytics,Risk prediction models},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\35QWN2WF\\Van Calster et al. - 2019 - Calibration the Achilles heel of predictive analy.pdf;C\:\\Users\\Zane\\Zotero\\storage\\HASZYFR3\\s12916-019-1466-7.html}
}

@article{vanvugt2015,
  title = {Validity of a Clinical Model to Predict Influenza in Patients Presenting with Symptoms of Lower Respiratory Tract Infection in Primary Care},
  author = {{van Vugt}, Saskia F and Broekhuizen, Berna DL and Zuithoff, Nicolaas PA and {van Essen}, Gerrit A and Ebell, Mark H and Coenen, Samuel and Ieven, Margareta and Lammens, Christine and Goossens, Herman and Butler, Chris C and Hood, Kerenza and Little, Paul and Verheij, Theo JM and {the GRACE Consortium}},
  year = {2015},
  month = aug,
  journal = {Family Practice},
  volume = {32},
  number = {4},
  pages = {408--414},
  issn = {0263-2136},
  doi = {10.1093/fampra/cmv039},
  abstract = {Valid clinical predictors of influenza in patients presenting with lower respiratory tract infection (LRTI) symptoms would provide adequate patient information and reassurance.Assessing the validity of an existing diagnostic model (Flu Score) to detect influenza in LRTI patients.A European diagnostic study recruited 1801 adult primary care patients with LRTI-like symptoms existing {$\leq$}7 days between October and April 2007\textendash 2010.History and physical examination findings were recorded and nasopharyngeal swabs taken. Polymerase chain reaction (PCR) for influenza A/B was performed as reference test. Diagnostic accuracy of the Flu Score (1\texttimes{} onset \&lt;48 hours + 2\texttimes{} myalgia + 1\texttimes{} chills or sweats + 2\texttimes{} fever and cough) was expressed as area under the curve (AUC), calibration slopes and likelihood ratios (LRs).A total of 273 patients (15\%) had influenza on PCR. The AUC of the Flu Score during winter months was 0.66 [95\% CI (95\% confidence internal) 0.63\textendash 0.70]. During peak influenza season, both influenza prevalence (24\%) and AUC were higher [0.71 (95\% CI 0.66\textendash 0.76], but calibration remained poor. The Flu Score assigned 64\% of the patients as `low-risk' (10\% had influenza, LR - 0.6). About 12\% were classified as `high risk' of whom 32\% had influenza (LR + 2.7). During peak influenza season, 60\% and 14\% of patients were classified as low and high risk, respectively, with influenza prevalences being 14\% (LR - 0.5) and 50\% (LR + 3.2).The Flu-Score attributes a small subgroup of patients with a high influenza risk (prevalence 32\%). However, clinical usefulness is limited because this group is small and the association between predicted and observed risks is poor. Considerable diagnostic imprecision remains when it comes to differentiating those with influenza on clinical grounds from the many other causes of LRTI in primary care. New point of care tests are required that accurately, rapidly and cost effectively detect influenza in patients with respiratory tract symptoms in primary care.},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\YXIAZT3S\\van Vugt et al. - 2015 - Validity of a clinical model to predict influenza .pdf;C\:\\Users\\Zane\\Zotero\\storage\\ICCBBAUP\\682394.html}
}

@article{vuichard-gysin2019,
  title = {Development and Validation of Clinical Prediction Models to Distinguish Influenza from Other Viruses Causing Acute Respiratory Infections in Children and Adults},
  author = {{Vuichard-Gysin}, Danielle and Mertz, Dominik and Pullenayegum, Eleanor and Singh, Pardeep and Smieja, Marek and Loeb, Mark},
  editor = {Lau, Eric HY},
  year = {2019},
  month = feb,
  journal = {PLoS ONE},
  volume = {14},
  number = {2},
  pages = {e0212050},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0212050},
  abstract = {Predictive models have been developed for influenza but have seldom been validated. Typically they have focused on patients meeting a definition of infection that includes fever. Less is known about how models perform when more symptoms are considered. We, therefore, aimed to create and internally validate predictive scores of acute respiratory infection (ARI) symptoms to diagnose influenza virus infection as confirmed by polymerase chain reaction (PCR) from respiratory specimens. Data from a completed trial to study the indirect effect of influenza immunization in Hutterite communities were randomly split into two independent groups for model derivation and validation. We applied different multivariable modelling techniques and constructed Receiver Operating Characteristics (ROC) curves to determine predictive indexes at different cut-points. From 2008\textendash 2011, 3288 first seasonal ARI episodes and 321 (9.8\%) influenza positive events occurred in 2202 individuals. In children up to 17 years, the significant predictors of influenza virus infection were fever, chills, and cough along with being of age 6 years and older. In adults, presence of chills and cough but not fever were highly specific for influenza virus infection (sensitivity 30\%, specificity 96\%). Performance of the models in the validation set was not significantly different. The predictors were consistently found to be significant irrespective of the multivariable technique. Symptomatic predictors of influenza virus infection vary between children and adults. The scores could assist clinicians in their test and treat decisions but the results need to be externally validated prior to application in clinical practice.},
  langid = {english},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\DHY535N8\\Vuichard-Gysin et al. - 2019 - Development and validation of clinical prediction .pdf}
}

@article{xiao2021,
  title = {Triage {{Modeling}} for {{Differential Diagnosis Between COVID-19}} and {{Human Influenza A Pneumonia}}: {{Classification}} and {{Regression Tree Analysis}}},
  shorttitle = {Triage {{Modeling}} for {{Differential Diagnosis Between COVID-19}} and {{Human Influenza A Pneumonia}}},
  author = {Xiao, Anling and Zhao, Huijuan and Xia, Jianbing and Zhang, Ling and Zhang, Chao and Ruan, Zhuoying and Mei, Nan and Li, Xun and Ma, Wuren and Wang, Zhuozhu and He, Yi and Lee, Jimmy and Zhu, Weiming and Tian, Dajun and Zhang, Kunkun and Zheng, Weiwei and Yin, Bo},
  year = {2021},
  journal = {Front Med (Lausanne)},
  volume = {8},
  pages = {673253},
  issn = {2296-858X},
  doi = {10.3389/fmed.2021.673253},
  abstract = {Background: The coronavirus disease 2019 (COVID-19) pandemic has lasted much longer than an influenza season, but the main signs, symptoms, and some imaging findings are similar in COVID-19 and influenza patients. The aim of the current study was to construct an accurate and robust model for initial screening and differential diagnosis of COVID-19 and influenza A. Methods: All patients in the study were diagnosed at Fuyang No. 2 People's Hospital, and they included 151 with COVID-19 and 155 with influenza A. The patients were randomly assigned to training set or a testing set at a 4:1 ratio. Predictor variables were selected based on importance, assessed by random forest algorithms, and analyzed to develop classification and regression tree models. Results: In the optimal model A, the best single predictor of COVID-19 patients was a normal or high level of low-density lipoprotein cholesterol, followed by low level of creatine kinase, then the presence of {$<$}3 respiratory symptoms, then a highest temperature on the first day of admission {$<$}38\textdegree C. In the suboptimal model B, the best single predictor of COVID-19 was a low eosinophil count, then a normal monocyte ratio, then a normal hematocrit value, then a highest temperature on the first day of admission of {$<$}37\textdegree C, then a complete lack of respiratory symptoms. Conclusions: The two models provide clinicians with a rapid triage tool. The optimal model can be used to developed countries/regions and major hospitals, and the suboptimal model can be used in underdeveloped regions and small hospitals.},
  langid = {english},
  pmcid = {PMC8382719},
  pmid = {34447759},
  keywords = {COVID-19,differential diagnosis,influenza A,rapid triage tools,regression tree analysis},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\WRVS9RNH\\Xiao et al. - 2021 - Triage Modeling for Differential Diagnosis Between.pdf}
}

@article{zapf2016,
  title = {Measuring Inter-Rater Reliability for Nominal Data - Which Coefficients and Confidence Intervals Are Appropriate?},
  author = {Zapf, Antonia and Castell, Stefanie and Morawietz, Lars and Karch, Andr{\'e}},
  year = {2016},
  month = aug,
  journal = {BMC Med Res Methodol},
  volume = {16},
  pages = {93},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0200-9},
  abstract = {BACKGROUND: Reliability of measurements is a prerequisite of medical research. For nominal data, Fleiss' kappa (in the following labelled as Fleiss' K) and Krippendorff's alpha provide the highest flexibility of the available reliability measures with respect to number of raters and categories. Our aim was to investigate which measures and which confidence intervals provide the best statistical properties for the assessment of inter-rater reliability in different situations. METHODS: We performed a large simulation study to investigate the precision of the estimates for Fleiss' K and Krippendorff's alpha and to determine the empirical coverage probability of the corresponding confidence intervals (asymptotic for Fleiss' K and bootstrap for both measures). Furthermore, we compared measures and confidence intervals in a real world case study. RESULTS: Point estimates of Fleiss' K and Krippendorff's alpha did not differ from each other in all scenarios. In the case of missing data (completely at random), Krippendorff's alpha provided stable estimates, while the complete case analysis approach for Fleiss' K led to biased estimates. For shifted null hypotheses, the coverage probability of the asymptotic confidence interval for Fleiss' K was low, while the bootstrap confidence intervals for both measures provided a coverage probability close to the theoretical one. CONCLUSIONS: Fleiss' K and Krippendorff's alpha with bootstrap confidence intervals are equally suitable for the analysis of reliability of complete nominal data. The asymptotic confidence interval for Fleiss' K should not be used. In the case of missing data or data or higher than nominal order, Krippendorff's alpha is recommended. Together with this article, we provide an R-script for calculating Fleiss' K and Krippendorff's alpha and their corresponding bootstrap confidence intervals.},
  langid = {english},
  pmcid = {PMC4974794},
  pmid = {27495131},
  keywords = {Algorithms,Bootstrap,Breast Neoplasms,Confidence interval,Confidence Intervals,Data Interpretation; Statistical,Female,Fleiss’ K,Fleiss’ kappa,Humans,Inter-rater heterogeneity,Krippendorff’s alpha,Observer Variation,Reproducibility of Results,Retrospective Studies},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\DSMQREW7\\Zapf et al. - 2016 - Measuring inter-rater reliability for nominal data.pdf}
}

@article{zec2017,
  title = {High {{Agreement}} and {{High Prevalence}}: {{The Paradox}} of {{Cohen}}'s {{Kappa}}},
  shorttitle = {High {{Agreement}} and {{High Prevalence}}},
  author = {Zec, Slavica and Soriani, Nicola and Comoretto, Rosanna and Baldi, Ileana},
  year = {2017},
  journal = {Open Nurs J},
  volume = {11},
  pages = {211--218},
  issn = {1874-4346},
  doi = {10.2174/1874434601711010211},
  abstract = {BACKGROUND: Cohen's Kappa is the most used agreement statistic in literature. However, under certain conditions, it is affected by a paradox which returns biased estimates of the statistic itself. OBJECTIVE: The aim of the study is to provide sufficient information which allows the reader to make an informed choice of the correct agreement measure, by underlining some optimal properties of Gwet's AC1 in comparison to Cohen's Kappa, using a real data example. METHOD: During the process of literature review, we have asked a panel of three evaluators to come up with a judgment on the quality of 57 randomized controlled trials assigning a score to each trial using the Jadad scale. The quality was evaluated according to the following dimensions: adopted design, randomization unit, type of primary endpoint. With respect to each of the above described features, the agreement between the three evaluators has been calculated using Cohen's Kappa statistic and Gwet's AC1 statistic and, finally, the values have been compared with the observed agreement. RESULTS: The values of the Cohen's Kappa statistic would lead to believe that the agreement levels for the variables Unit, Design and Primary Endpoints are totally unsatisfactory. The AC1 statistic, on the contrary, shows plausible values which are in line with the respective values of the observed concordance. CONCLUSION: We conclude that it would always be appropriate to adopt the AC1 statistic, thus bypassing any risk of incurring the paradox and drawing wrong conclusions about the results of agreement analysis.},
  langid = {english},
  pmcid = {PMC5712640},
  pmid = {29238424},
  keywords = {Agreement statistics,Cohen's Kappa,Concordance analysis,Gwet’s AC1,Inter-rater agreement,Quality assessment of RCT},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\3WXYYWLI\\Zec et al. - 2017 - High Agreement and High Prevalence The Paradox of.pdf}
}

@article{zimmerman2016,
  title = {Classification and {{Regression Tree}} ({{CART}}) Analysis to Predict Influenza in Primary Care Patients},
  author = {Zimmerman, Richard K. and Balasubramani, G. K. and Nowalk, Mary Patricia and Eng, Heather and Urbanski, Leonard and Jackson, Michael L. and Jackson, Lisa A. and McLean, Huong Q. and Belongia, Edward A. and Monto, Arnold S. and Malosh, Ryan E. and Gaglani, Manjusha and Clipper, Lydia and Flannery, Brendan and Wisniewski, Stephen R.},
  year = {2016},
  month = sep,
  journal = {BMC Infect Dis},
  volume = {16},
  number = {1},
  pages = {503},
  issn = {1471-2334},
  doi = {10.1186/s12879-016-1839-x},
  abstract = {BACKGROUND: The use of neuraminidase-inhibiting anti-viral medication to treat influenza is relatively infrequent. Rapid, cost-effective methods for diagnosing influenza are needed to enable appropriate prescribing. Multi-viral respiratory panels using reverse transcription polymerase chain reaction (PCR) assays to diagnose influenza are accurate but expensive and more time-consuming than low sensitivity rapid influenza tests. Influenza clinical decision algorithms are both rapid and inexpensive, but most are based on regression analyses that do not account for higher order interactions. This study used classification and regression trees (CART) modeling to estimate probabilities of influenza. METHODS: Eligible enrollees\,{$\geq$}\,5~years old (n\,=\,4,173) who presented at ambulatory centers for treatment of acute respiratory illness ({$\leq$}7~days) with cough or fever in 2011-2012, provided nasal and pharyngeal swabs for PCR testing for influenza, information on demographics, symptoms, personal characteristics and self-reported influenza vaccination status. RESULTS: Antiviral medication was prescribed for just 15~\% of those with PCR-confirmed influenza. An algorithm that included fever, cough, and fatigue had sensitivity of 84~\%, specificity of 48~\%, positive predictive value (PPV) of 23~\% and negative predictive value (NPV) of 94~\% for the development sample. CONCLUSIONS: The CART algorithm has good sensitivity and high NPV, but low PPV for identifying influenza among outpatients {$\geq$}5~years. Thus, it is good at identifying a group who do not need testing or antivirals and had fair to good predictive performance for influenza. Further testing of the algorithm in other influenza seasons would help to optimize decisions for lab testing or treatment.},
  langid = {english},
  pmcid = {PMC5034457},
  pmid = {27659721},
  keywords = {Clinical decision tools,Influenza,Recursive partitioning},
  file = {C\:\\Users\\Zane\\Zotero\\storage\\DDHB535W\\Zimmerman et al. - 2016 - Classification and Regression Tree (CART) analysis.pdf}
}


